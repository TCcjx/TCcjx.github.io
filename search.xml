<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Qwen2技术报告</title>
      <link href="//2025-12-03-post26_Qwen2%20Technical%20report/"/>
      <url>//2025-12-03-post26_Qwen2%20Technical%20report/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Qwen2的技术报告我大概花了一上午读完了，但是后面评测介绍评测性能的实验分析相关内容并没有细看，只是大致的给过了一眼，重点关注了前面模型架构以及训练部分的创新。</p><h2 id="1-主要内容"><a href="#1-主要内容" class="headerlink" title="1.主要内容"></a>1.主要内容</h2><p>Qwen2系列开源模型，主要包括<strong>Base Model</strong>(只是预训练，没有进行人类偏好对齐的基础模型) 和 针对对话和agent进行单轮和多轮指令微调的<strong>指令微调模型</strong>，这次发布的稠密模型，主要包括有四个尺寸的模型，分别是<strong>0.5B、7B、14B、72B</strong>的模型，还有一个<strong>57-14B</strong>的<strong>MOE混合专家模型</strong>。Qwen2相比前一代模型在数据集质量和规模上都有较大提升，后训练阶段是采用了 <strong>监督微调</strong>和<strong>DPO直接偏好对齐</strong>。</p><h2 id="2-细节部分"><a href="#2-细节部分" class="headerlink" title="2.细节部分"></a>2.细节部分</h2><h3 id="分词："><a href="#分词：" class="headerlink" title="分词："></a><strong>分词：</strong></h3><p>bpe分词，该分词器展现出高编码效率，因为bpe分词方法的压缩率更好，所有模型的词表大小都是151646，其中151643是regular token，另外3个token是control token，在实际训练中，因为考虑分布式训练，因此嵌入的有效大小实际上更大。</p><h3 id="模型架构："><a href="#模型架构：" class="headerlink" title="模型架构："></a>模型架构：</h3><p>Qwen2密集模型的架构包括多个Transformer层，每层都配备了因果注意力机制和前馈神经网络（FFN）。与Qwen的主要区别如下：</p><ul><li><strong>分组查询注意力</strong>：我们采用了分组查询注意力（Grouped Query Attention，<a href="https://zhida.zhihu.com/search?content_id=245747683&content_type=Article&match_order=1&q=GQA&zhida_source=entity">GQA</a>，Ainslie等人，2023）而不是传统的多头注意力（multi-head attention，MHA）。GQA在推理期间优化了KV缓存的使用，显著提高了吞吐量。不同模型大小的详细KV头配置在第2.2.3节报告。</li><li><strong>双块注意力与<a href="https://zhida.zhihu.com/search?content_id=245747683&content_type=Article&match_order=1&q=YARN&zhida_source=entity">YARN</a></strong>：为了扩大Qwen2的上下文窗口，我们实现了双块注意力（Dual Chunk Attention，<a href="https://zhida.zhihu.com/search?content_id=245747683&content_type=Article&match_order=1&q=DCA&zhida_source=entity">DCA</a>，An等人，2024），它将长序列分割成可管理的长度块。如果输入可以在一个块中处理，DCA产生与原始注意力相同的结果。否则，DCA有助于在块内和跨块之间有效地捕获相对位置信息，从而提高长上下文性能。此外，我们还采用了<strong>YARN</strong>（Peng等人，2023）来重新调整注意力权重，以实现更好的长度外推。</li></ul><p>我们还沿用了Qwen的使用，包括<strong>SwiGLU</strong>（Dauphin等人，2017）作为激活函数，旋转位置嵌入（<strong><a href="https://zhida.zhihu.com/search?content_id=245747683&content_type=Article&match_order=1&q=RoPE&zhida_source=entity">RoPE</a></strong>，Su等人，2024）作为位置嵌入，<strong>QKV偏置</strong>（Su，2023）用于注意力，<strong><a href="https://zhida.zhihu.com/search?content_id=245747683&content_type=Article&match_order=1&q=RMSNorm&zhida_source=entity">RMSNorm</a></strong>（Jiang等人，2023b）和预归一化用于训练稳定性。</p><h3 id="MOE混合专家模型"><a href="#MOE混合专家模型" class="headerlink" title="MOE混合专家模型"></a>MOE混合专家模型</h3><p>在qwen2中，采用了更多尺寸更小的单个专家，一次性激活的专家数量更多，从而可以提供更多的专家类型，并且将<strong>共享专家和特定路由专家</strong>整合到<strong>MoE层内促进了在各种任务中应用共享专家，又保留了其他专家在特定路由场景中选择性使用。引入共享和专门的专家为开发MoE路由机制提供了一种更适应性和有效的方法。</strong></p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Qwen2 </tag>
            
            <tag> 技术报告 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Q-learning及DQN算法</title>
      <link href="//2025-11-25-post25_Q-learning%E5%8F%8ADQN%E7%AE%97%E6%B3%95/"/>
      <url>//2025-11-25-post25_Q-learning%E5%8F%8ADQN%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Q-learning-算法"><a href="#1-Q-learning-算法" class="headerlink" title="1.Q-learning 算法"></a>1.Q-learning 算法</h2><p><strong>核心公式：</strong></p><p><img src="/2025-11-25-post25_Q-learning%E5%8F%8ADQN%E7%AE%97%E6%B3%95/4.png"></p><p>Q-learning算法是一种免模型的算法，核心思想就是基于价值，实际上就是在填一张状态-价值表，初始化都是为0，基于当前状态，计算出所有动作的reward分数，在$\epsilon$的概率下会选择随机的动作，1-$\epsilon$的概率下会选择最高分数的工作，$\epsilon$会随着学习的过程逐步衰减，这个学习过程也被称为”先探索再稳定”，实际上整个学习过程，就是在不断的去填这张状态-动作价值表，这张表相当于策略，在后面的决策动作时，会依据这张表来采取相应的动作(action).</p><p>当时Q-learning主要存在以下缺陷：</p><ul><li>1、存在维度灾难问题</li><li>2、只能处理离散状态的决策问题，不能处理连续状态的决策问题</li><li>3、训练不稳定</li></ul><p><strong>因此，DQN的提出，用深度学习模型来近似动作价值函数的方法，解决了Q-learning维度灾难的问题、只能处理离散状态的问题，并且改善了训练的稳定性。</strong></p><h2 id="2-DQN算法"><a href="#2-DQN算法" class="headerlink" title="2.DQN算法"></a>2.DQN算法</h2><p><strong>主要思想：</strong></p><p><img src="/2025-11-25-post25_Q-learning%E5%8F%8ADQN%E7%AE%97%E6%B3%95/1.png"></p><p>DQN主要有两个改进点：</p><p><strong>一、经验回放机制</strong></p><p>当产生一条新的数据时，先$ e_t &#x3D; (S_t, A_t, R_t, S_{t+1}, \text{Done})$,不会立即用这条数据来进行训练，而是先把这条数据存放到Repaly Buffer中（大小为N的参数），如果存满了，则会按照先进先出的原则，丢弃掉最早进入Buffer的数据，训练时，会随机从Buffer中取出一条数据来进行训练。</p><p><strong>解决的问题：</strong></p><ul><li><strong>1、打破数据的时间相关性：</strong> 原本的序列数据，存在相关性，通过经验回放机制，可以打破时间相关性，学习到的规律更通用。</li><li><strong>2、样本可以复用</strong>：原本可以复用，解决之前数据用一次就丢掉的问题，一条数据可能被多次抽中进行训练</li><li><strong>3、提高训练稳定性</strong></li></ul><p>**细节：**经验回放机制在取数据的时候，会按照一定概率取随机取数据或取最大的Q值动作，这个过程是为了保证训练过程中，先进行探索再逐步稳定。</p><p><strong>二、使用策略网络和目标网络</strong></p><ul><li>这样可以<strong>提高训练稳定性</strong>，<strong>避免Q值发散</strong>，在实际中，先更新策略网络，把目标值进行固定，达到设定的步数c时，才会将策略网络复制更新到目标网络中</li></ul><p><strong>解决的问题：</strong></p><p>这样可以提高训练稳定性，避免Q值发散，在实际中，先更新策略网络，把目标值进行固定，达到设定的步数c时，才会将策略网络复制更新到目标网络中。</p><p>**为什么要这样做？**答：因为原本的目标网络和策略网路的参数存在相关性，状态的改变对两者的学习都有影响，通过先固定目标网络，可以避免单个样本造成的错误估计，避免Q值发散，使得网络训练更加稳定。</p><h2 id="3-DQN算法实现过程"><a href="#3-DQN算法实现过程" class="headerlink" title="3.DQN算法实现过程"></a>3.DQN算法实现过程</h2><p><strong>1.策略网络和目标网路的网络结构</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_states,n_actions,hidden_dim=<span class="number">128</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; 初始化q网络，为全连接网络</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(MLP, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(n_states, hidden_dim) <span class="comment"># 输入层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(hidden_dim,hidden_dim) <span class="comment"># 隐藏层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(hidden_dim, n_actions) <span class="comment"># 输出层</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 各层对应的激活函数</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x)) </span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc2(x))</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc3(x)</span><br></pre></td></tr></table></figure><p><strong>2.经验回放机制实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque <span class="comment"># 队列</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ReplayBuffer</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, capacity: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.capacity = capacity</span><br><span class="line">        <span class="variable language_">self</span>.buffer = deque(maxlen=<span class="variable language_">self</span>.capacity)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">push</span>(<span class="params">self,transitions</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 存储transition到经验回放中</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.buffer.append(transitions)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">self, batch_size: <span class="built_in">int</span>, sequential: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">if</span> batch_size &gt; <span class="built_in">len</span>(<span class="variable language_">self</span>.buffer): <span class="comment"># 如果批量大小大于经验回放的容量，则取经验回放的容量</span></span><br><span class="line">            batch_size = <span class="built_in">len</span>(<span class="variable language_">self</span>.buffer)</span><br><span class="line">        <span class="keyword">if</span> sequential: <span class="comment"># 顺序采样</span></span><br><span class="line">            rand = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.buffer) - batch_size)</span><br><span class="line">            batch = [<span class="variable language_">self</span>.buffer[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rand, rand + batch_size)]</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">zip</span>(*batch)</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 随机采样</span></span><br><span class="line">            batch = random.sample(<span class="variable language_">self</span>.buffer, batch_size)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">zip</span>(*batch)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clear</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 清空经验回放</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.buffer.clear()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 返回当前存储的量</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.buffer)</span><br></pre></td></tr></table></figure><p><strong>3.DQN智能体实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DQN</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,model,memory,cfg</span>): <span class="comment"># !初始化超参数、 模型、以及经验回放池</span></span><br><span class="line">        <span class="variable language_">self</span>.n_actions = cfg[<span class="string">&#x27;n_actions&#x27;</span>]  </span><br><span class="line">        <span class="variable language_">self</span>.device = torch.device(cfg[<span class="string">&#x27;device&#x27;</span>]) </span><br><span class="line">        <span class="variable language_">self</span>.gamma = cfg[<span class="string">&#x27;gamma&#x27;</span>] <span class="comment"># 奖励的折扣因子</span></span><br><span class="line">        <span class="comment"># e-greedy策略相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.sample_count = <span class="number">0</span>  <span class="comment"># 用于epsilon的衰减计数</span></span><br><span class="line">        <span class="variable language_">self</span>.epsilon = cfg[<span class="string">&#x27;epsilon_start&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.sample_count = <span class="number">0</span>  </span><br><span class="line">        <span class="variable language_">self</span>.epsilon_start = cfg[<span class="string">&#x27;epsilon_start&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.epsilon_end = cfg[<span class="string">&#x27;epsilon_end&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.epsilon_decay = cfg[<span class="string">&#x27;epsilon_decay&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.batch_size = cfg[<span class="string">&#x27;batch_size&#x27;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.policy_net = model.to(<span class="variable language_">self</span>.device)</span><br><span class="line">        <span class="variable language_">self</span>.target_net = model.to(<span class="variable language_">self</span>.device)</span><br><span class="line">        <span class="comment"># 复制策略网络参数到目标网络</span></span><br><span class="line">        <span class="keyword">for</span> target_param, param <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="variable language_">self</span>.target_net.parameters(),<span class="variable language_">self</span>.policy_net.parameters()): </span><br><span class="line">            target_param.data.copy_(param.data)</span><br><span class="line">        <span class="variable language_">self</span>.optimizer = optim.Adam(<span class="variable language_">self</span>.policy_net.parameters(), lr=cfg[<span class="string">&#x27;lr&#x27;</span>]) <span class="comment"># 优化器</span></span><br><span class="line">        <span class="variable language_">self</span>.memory = memory <span class="comment"># 经验回放</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 采样动作</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="variable language_">self</span>.sample_count += <span class="number">1</span></span><br><span class="line">        <span class="comment"># epsilon指数衰减</span></span><br><span class="line">        <span class="variable language_">self</span>.epsilon = <span class="variable language_">self</span>.epsilon_end + (<span class="variable language_">self</span>.epsilon_start - <span class="variable language_">self</span>.epsilon_end) * \</span><br><span class="line">            math.exp(-<span class="number">1.</span> * <span class="variable language_">self</span>.sample_count / <span class="variable language_">self</span>.epsilon_decay) </span><br><span class="line">        <span class="keyword">if</span> random.random() &gt; <span class="variable language_">self</span>.epsilon: <span class="comment"># 取最大Q值</span></span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                state = torch.tensor(state, device=<span class="variable language_">self</span>.device, dtype=torch.float32).unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">                q_values = <span class="variable language_">self</span>.policy_net(state)</span><br><span class="line">                action = q_values.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].item() <span class="comment"># choose action corresponding to the maximum q value 最大Q值的下标</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># 随机采样</span></span><br><span class="line">            action = random.randrange(<span class="variable language_">self</span>.n_actions)</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"><span class="meta">    @torch.no_grad() </span><span class="comment"># 不计算梯度，该装饰器效果等同于with torch.no_grad()：</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 预测动作</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        state = torch.tensor(state, device=<span class="variable language_">self</span>.device, dtype=torch.float32).unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line">        q_values = <span class="variable language_">self</span>.policy_net(state)</span><br><span class="line">        action = q_values.<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">1</span>].item() <span class="comment"># choose action corresponding to the maximum q value</span></span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.memory) &lt; <span class="variable language_">self</span>.batch_size: <span class="comment"># !当经验回放中不满足一个批量时，不更新策略</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># 从经验回放中随机采样一个批量的转移(transition)</span></span><br><span class="line">        state_batch, action_batch, reward_batch, next_state_batch, done_batch = <span class="variable language_">self</span>.memory.sample(</span><br><span class="line">            <span class="variable language_">self</span>.batch_size)</span><br><span class="line">        <span class="comment"># 将数据转换为tensor</span></span><br><span class="line">        state_batch = torch.tensor(np.array(state_batch), device=<span class="variable language_">self</span>.device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        action_batch = torch.tensor(action_batch, device=<span class="variable language_">self</span>.device).unsqueeze(<span class="number">1</span>)  </span><br><span class="line">        reward_batch = torch.tensor(reward_batch, device=<span class="variable language_">self</span>.device, dtype=torch.<span class="built_in">float</span>)  </span><br><span class="line">        next_state_batch = torch.tensor(np.array(<span class="built_in">object</span>=next_state_batch), device=<span class="variable language_">self</span>.device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        done_batch = torch.tensor(np.float32(done_batch), device=<span class="variable language_">self</span>.device)</span><br><span class="line">        q_values = <span class="variable language_">self</span>.policy_net(state_batch).gather(dim=<span class="number">1</span>, index=action_batch) <span class="comment"># 计算当前状态(s_t,a)对应的Q(s_t, a)</span></span><br><span class="line">        next_q_values = <span class="variable language_">self</span>.target_net(next_state_batch).<span class="built_in">max</span>(<span class="number">1</span>)[<span class="number">0</span>].detach() <span class="comment"># 计算下一时刻的状态(s_t_,a)对应的Q值</span></span><br><span class="line">        <span class="comment"># 计算期望的Q值，对于终止状态，此时done_batch[0]=1, 对应的expected_q_value等于reward</span></span><br><span class="line">        expected_q_values = reward_batch + <span class="variable language_">self</span>.gamma * next_q_values * (<span class="number">1</span>-done_batch)</span><br><span class="line">        loss = nn.MSELoss()(q_values, expected_q_values.unsqueeze(<span class="number">1</span>))  <span class="comment"># 计算均方根损失</span></span><br><span class="line">        <span class="comment"># 优化更新模型</span></span><br><span class="line">        <span class="variable language_">self</span>.optimizer.zero_grad()  </span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># clip防止梯度爆炸</span></span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> <span class="variable language_">self</span>.policy_net.parameters():  <span class="comment"># !进行梯度裁剪</span></span><br><span class="line">            param.grad.data.clamp_(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.optimizer.step()  <span class="comment"># 进行梯度更新</span></span><br></pre></td></tr></table></figure><p><strong>3.训练测试函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">cfg, env, agent</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 训练</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始训练！&quot;</span>)</span><br><span class="line">    rewards = []  <span class="comment"># 记录所有回合的奖励</span></span><br><span class="line">    steps = []</span><br><span class="line">    <span class="keyword">for</span> i_ep <span class="keyword">in</span> <span class="built_in">range</span>(cfg[<span class="string">&#x27;train_eps&#x27;</span>]):</span><br><span class="line">        ep_reward = <span class="number">0</span>  <span class="comment"># 记录一回合内的奖励</span></span><br><span class="line">        ep_step = <span class="number">0</span></span><br><span class="line">        state = env.reset(seed=cfg[<span class="string">&#x27;seed&#x27;</span>]) <span class="keyword">if</span> cfg[<span class="string">&#x27;seed&#x27;</span>] != <span class="number">0</span> <span class="keyword">else</span> env.reset()  <span class="comment"># 重置环境，返回初始状态</span></span><br><span class="line">        <span class="comment"># 处理新版gym返回的(state, info)元组</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">tuple</span>):</span><br><span class="line">            state = state[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cfg[<span class="string">&#x27;ep_max_steps&#x27;</span>]):</span><br><span class="line">            ep_step += <span class="number">1</span></span><br><span class="line">            action = agent.sample_action(state)  <span class="comment"># 选择动作</span></span><br><span class="line">            result = env.step(action)  <span class="comment"># 更新环境，返回transition</span></span><br><span class="line">            <span class="comment"># 处理不同版本的返回值</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(result) == <span class="number">5</span>:</span><br><span class="line">                next_state, reward, terminated, truncated, _ = result</span><br><span class="line">                done = terminated <span class="keyword">or</span> truncated</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                next_state, reward, done, _ = result</span><br><span class="line">            agent.memory.push((state, action, reward, next_state, done))  <span class="comment"># 保存transition</span></span><br><span class="line">            state = next_state  <span class="comment"># 更新下一个状态</span></span><br><span class="line">            agent.update()  <span class="comment"># 更新智能体</span></span><br><span class="line">            ep_reward += reward  <span class="comment"># 累加奖励</span></span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> (i_ep + <span class="number">1</span>) % cfg[<span class="string">&#x27;target_update&#x27;</span>] == <span class="number">0</span>:  <span class="comment"># 智能体目标网络更新</span></span><br><span class="line">            agent.target_net.load_state_dict(agent.policy_net.state_dict())</span><br><span class="line">        steps.append(ep_step)</span><br><span class="line">        rewards.append(ep_reward)</span><br><span class="line">        <span class="keyword">if</span> (i_ep + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;回合：<span class="subst">&#123;i_ep+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;cfg[<span class="string">&#x27;train_eps&#x27;</span>]&#125;</span>，奖励：<span class="subst">&#123;ep_reward:<span class="number">.2</span>f&#125;</span>，Epislon：<span class="subst">&#123;agent.epsilon:<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;完成训练！&quot;</span>)</span><br><span class="line">    env.close()</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;rewards&#x27;</span>:rewards&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">cfg, env, agent</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始测试！&quot;</span>)</span><br><span class="line">    rewards = []  <span class="comment"># 记录所有回合的奖励</span></span><br><span class="line">    steps = []</span><br><span class="line">    <span class="keyword">for</span> i_ep <span class="keyword">in</span> <span class="built_in">range</span>(cfg[<span class="string">&#x27;test_eps&#x27;</span>]):</span><br><span class="line">        ep_reward = <span class="number">0</span>  <span class="comment"># 记录一回合内的奖励</span></span><br><span class="line">        ep_step = <span class="number">0</span></span><br><span class="line">        state = env.reset()  <span class="comment"># 重置环境，返回初始状态</span></span><br><span class="line">        <span class="comment"># 处理新版gym返回的(state, info)元组</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">tuple</span>):</span><br><span class="line">            state = state[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(cfg[<span class="string">&#x27;ep_max_steps&#x27;</span>]):</span><br><span class="line">            ep_step+=<span class="number">1</span></span><br><span class="line">            action = agent.predict_action(state)  <span class="comment"># 选择动作</span></span><br><span class="line">            result = env.step(action)  <span class="comment"># 更新环境，返回transition</span></span><br><span class="line">            <span class="comment"># 处理不同版本的返回值</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(result) == <span class="number">5</span>:</span><br><span class="line">                next_state, reward, terminated, truncated, _ = result</span><br><span class="line">                done = terminated <span class="keyword">or</span> truncated</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                next_state, reward, done, _ = result</span><br><span class="line">            state = next_state  <span class="comment"># 更新下一个状态</span></span><br><span class="line">            ep_reward += reward  <span class="comment"># 累加奖励</span></span><br><span class="line">            <span class="keyword">if</span> done:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        steps.append(ep_step)</span><br><span class="line">        rewards.append(ep_reward)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;回合：<span class="subst">&#123;i_ep+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;cfg[<span class="string">&#x27;test_eps&#x27;</span>]&#125;</span>，奖励：<span class="subst">&#123;ep_reward:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;完成测试&quot;</span>)</span><br><span class="line">    env.close()</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&#x27;rewards&#x27;</span>:rewards&#125;</span><br></pre></td></tr></table></figure><p><strong>4.定义环境</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">all_seed</span>(<span class="params">env,seed = <span class="number">1</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 万能的seed函数</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed) <span class="comment"># config for CPU</span></span><br><span class="line">    torch.cuda.manual_seed(seed) <span class="comment"># config for GPU</span></span><br><span class="line">    os.environ[<span class="string">&#x27;PYTHONHASHSEED&#x27;</span>] = <span class="built_in">str</span>(seed) <span class="comment"># config for python scripts</span></span><br><span class="line">    <span class="comment"># config for cudnn</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    torch.backends.cudnn.enabled = <span class="literal">False</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">env_agent_config</span>(<span class="params">cfg</span>):</span><br><span class="line">    env = gym.make(cfg[<span class="string">&#x27;env_name&#x27;</span>]) <span class="comment"># 创建环境</span></span><br><span class="line">    <span class="keyword">if</span> cfg[<span class="string">&#x27;seed&#x27;</span>] !=<span class="number">0</span>:</span><br><span class="line">        all_seed(env,seed=cfg[<span class="string">&#x27;seed&#x27;</span>])</span><br><span class="line">    n_states = env.observation_space.shape[<span class="number">0</span>]</span><br><span class="line">    n_actions = env.action_space.n</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;状态空间维度：<span class="subst">&#123;n_states&#125;</span>，动作空间维度：<span class="subst">&#123;n_actions&#125;</span>&quot;</span>)</span><br><span class="line">    cfg.update(&#123;<span class="string">&quot;n_states&quot;</span>:n_states,<span class="string">&quot;n_actions&quot;</span>:n_actions&#125;) <span class="comment"># 更新n_states和n_actions到cfg参数中</span></span><br><span class="line">    model = MLP(n_states, n_actions, hidden_dim = cfg[<span class="string">&#x27;hidden_dim&#x27;</span>]) <span class="comment"># 创建模型</span></span><br><span class="line">    memory = ReplayBuffer(cfg[<span class="string">&#x27;memory_capacity&#x27;</span>])</span><br><span class="line">    agent = DQN(model,memory,cfg)</span><br><span class="line">    <span class="keyword">return</span> env,agent</span><br></pre></td></tr></table></figure><p><strong>5.参数设置及功能函数实现</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_args</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot; 超参数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&quot;hyperparameters&quot;</span>)      </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--algo_name&#x27;</span>,default=<span class="string">&#x27;DQN&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&quot;name of algorithm&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--env_name&#x27;</span>,default=<span class="string">&#x27;CartPole-v0&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&quot;name of environment&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--train_eps&#x27;</span>,default=<span class="number">200</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,<span class="built_in">help</span>=<span class="string">&quot;episodes of training&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--test_eps&#x27;</span>,default=<span class="number">20</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,<span class="built_in">help</span>=<span class="string">&quot;episodes of testing&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--ep_max_steps&#x27;</span>,default = <span class="number">100000</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,<span class="built_in">help</span>=<span class="string">&quot;steps per episode, much larger value can simulate infinite steps&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gamma&#x27;</span>,default=<span class="number">0.95</span>,<span class="built_in">type</span>=<span class="built_in">float</span>,<span class="built_in">help</span>=<span class="string">&quot;discounted factor&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epsilon_start&#x27;</span>,default=<span class="number">0.95</span>,<span class="built_in">type</span>=<span class="built_in">float</span>,<span class="built_in">help</span>=<span class="string">&quot;initial value of epsilon&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epsilon_end&#x27;</span>,default=<span class="number">0.01</span>,<span class="built_in">type</span>=<span class="built_in">float</span>,<span class="built_in">help</span>=<span class="string">&quot;final value of epsilon&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epsilon_decay&#x27;</span>,default=<span class="number">500</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,<span class="built_in">help</span>=<span class="string">&quot;decay rate of epsilon, the higher value, the slower decay&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>,default=<span class="number">0.0001</span>,<span class="built_in">type</span>=<span class="built_in">float</span>,<span class="built_in">help</span>=<span class="string">&quot;learning rate&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--memory_capacity&#x27;</span>,default=<span class="number">100000</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,<span class="built_in">help</span>=<span class="string">&quot;memory capacity&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>,default=<span class="number">64</span>,<span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--target_update&#x27;</span>,default=<span class="number">4</span>,<span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--hidden_dim&#x27;</span>,default=<span class="number">256</span>,<span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--device&#x27;</span>,default=<span class="string">&#x27;cpu&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>,<span class="built_in">help</span>=<span class="string">&quot;cpu or cuda&quot;</span>) </span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>,default=<span class="number">10</span>,<span class="built_in">type</span>=<span class="built_in">int</span>,<span class="built_in">help</span>=<span class="string">&quot;seed&quot;</span>)   </span><br><span class="line">    args = parser.parse_args([])</span><br><span class="line">    args = &#123;**<span class="built_in">vars</span>(args)&#125;  <span class="comment"># 转换成字典类型    </span></span><br><span class="line">    <span class="comment">## 打印超参数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;超参数&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join([<span class="string">&#x27;=&#x27;</span>]*<span class="number">80</span>))</span><br><span class="line">    tplt = <span class="string">&quot;&#123;:^20&#125;\t&#123;:^20&#125;\t&#123;:^20&#125;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(<span class="string">&quot;Name&quot;</span>, <span class="string">&quot;Value&quot;</span>, <span class="string">&quot;Type&quot;</span>))</span><br><span class="line">    <span class="keyword">for</span> k,v <span class="keyword">in</span> args.items():</span><br><span class="line">        <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(k,v,<span class="built_in">str</span>(<span class="built_in">type</span>(v))))   </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join([<span class="string">&#x27;=&#x27;</span>]*<span class="number">80</span>))      </span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">smooth</span>(<span class="params">data, weight=<span class="number">0.9</span></span>):  </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;用于平滑曲线，类似于Tensorboard中的smooth曲线</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    last = data[<span class="number">0</span>] </span><br><span class="line">    smoothed = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> data:</span><br><span class="line">        smoothed_val = last * weight + (<span class="number">1</span> - weight) * point  <span class="comment"># 计算平滑值</span></span><br><span class="line">        smoothed.append(smoothed_val)                    </span><br><span class="line">        last = smoothed_val                                </span><br><span class="line">    <span class="keyword">return</span> smoothed</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_rewards</span>(<span class="params">rewards,cfg, tag=<span class="string">&#x27;train&#x27;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 画图</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    sns.<span class="built_in">set</span>()</span><br><span class="line">    plt.figure()  <span class="comment"># 创建一个图形实例，方便同时多画几个图</span></span><br><span class="line">    plt.title(<span class="string">f&quot;<span class="subst">&#123;tag&#125;</span>ing curve on <span class="subst">&#123;cfg[<span class="string">&#x27;device&#x27;</span>]&#125;</span> of <span class="subst">&#123;cfg[<span class="string">&#x27;algo_name&#x27;</span>]&#125;</span> for <span class="subst">&#123;cfg[<span class="string">&#x27;env_name&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;epsiodes&#x27;</span>)</span><br><span class="line">    plt.plot(rewards, label=<span class="string">&#x27;rewards&#x27;</span>)</span><br><span class="line">    plt.plot(smooth(rewards), label=<span class="string">&#x27;smoothed&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>6.训练</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取参数</span></span><br><span class="line">cfg = get_args() </span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line"><span class="built_in">env</span>, agent = env_agent_config(cfg)</span><br><span class="line">res_dic = train(cfg, <span class="built_in">env</span>, agent)</span><br><span class="line"> </span><br><span class="line">plot_rewards(res_dic[<span class="string">&#x27;rewards&#x27;</span>], cfg, tag=<span class="string">&quot;train&quot;</span>)  </span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">res_dic = <span class="built_in">test</span>(cfg, <span class="built_in">env</span>, agent)</span><br><span class="line">plot_rewards(res_dic[<span class="string">&#x27;rewards&#x27;</span>], cfg, tag=<span class="string">&quot;test&quot;</span>)  <span class="comment"># 画出结果</span></span><br></pre></td></tr></table></figure><h2 id="4-训练过程图"><a href="#4-训练过程图" class="headerlink" title="4.训练过程图"></a>4.训练过程图</h2><p><img src="/2025-11-25-post25_Q-learning%E5%8F%8ADQN%E7%AE%97%E6%B3%95/2.png"></p><p><img src="/2025-11-25-post25_Q-learning%E5%8F%8ADQN%E7%AE%97%E6%B3%95/3.png"></p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DQN算法 </tag>
            
            <tag> Q-learning </tag>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博士屯TalkShow阅读文献总结</title>
      <link href="//2025-11-23-post24_%E5%8D%9A%E5%A3%AB%E5%B1%AFTalkShow%E9%98%85%E8%AF%BB%E6%96%87%E7%8C%AE%E6%80%BB%E7%BB%93/"/>
      <url>//2025-11-23-post24_%E5%8D%9A%E5%A3%AB%E5%B1%AFTalkShow%E9%98%85%E8%AF%BB%E6%96%87%E7%8C%AE%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="1-研究性论文-整体内容结构"><a href="#1-研究性论文-整体内容结构" class="headerlink" title="1.研究性论文-整体内容结构"></a>1.研究性论文-整体内容结构</h2><p>1、Abstract - 了解文章整体核心内容<br>2、Introduction - 问题和贡献<br>3、Related work - 小型综述性介绍<br>4、Method - 框架图<br>5、Experiment - 实验类型</p><h2 id="2-综述性论文"><a href="#2-综述性论文" class="headerlink" title="2.综述性论文"></a>2.综述性论文</h2><p>1、分类<br>2、未来方向</p><h2 id="3-阅读重点"><a href="#3-阅读重点" class="headerlink" title="3.阅读重点"></a>3.阅读重点</h2><p>1、文章解决的问题及方法（或者文章提出的问题）<br>2、可能存在的问题和解决方法<br>3、不必过度关注实验结果<br>4、终点关注方法的框架图<br>5、实验用到的方法和实验内容</p><h2 id="4、学会利用大模型来进行快速阅读总结"><a href="#4、学会利用大模型来进行快速阅读总结" class="headerlink" title="4、学会利用大模型来进行快速阅读总结"></a>4、学会利用大模型来进行快速阅读总结</h2><ul><li>大模型可能会出现一些总结问题，可能有一定误差</li><li>善用提示词</li></ul>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文献阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>与远端服务器进行文件传输同步的方式总结</title>
      <link href="//2025-10-14-post23_%E4%B8%8E%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%90%8C%E6%AD%A5%E7%9A%84%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/"/>
      <url>//2025-10-14-post23_%E4%B8%8E%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%90%8C%E6%AD%A5%E7%9A%84%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul><li>1、通过git及google网盘直接down到服务器(不推荐)</li><li>2、使用Vscode中SFTP插件与服务器进行文件传输</li><li>3、使用文件传输工具进行可视化的文件传输</li></ul><h2 id="1、通过git及google网盘直接down到服务器-不推荐"><a href="#1、通过git及google网盘直接down到服务器-不推荐" class="headerlink" title="1、通过git及google网盘直接down到服务器(不推荐)"></a>1、通过git及google网盘直接down到服务器(不推荐)</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;一般服务器都是linux的系统，自带git，当文件不是很大的时候，可以通过先将项目文件传输到git仓库，再git clone 到服务器上，当然这也是比较愚笨的办法。如果文件较大，可以通过google网盘，先将项目文件上传到google网盘保存，再通过下载命令下载到服务器上即可，以上方法都是实在没办法的时候 ，才采用的方法。</p><h2 id="2、使用Vscode中SFTP插件与服务器进行文件传输"><a href="#2、使用Vscode中SFTP插件与服务器进行文件传输" class="headerlink" title="2、使用Vscode中SFTP插件与服务器进行文件传输"></a>2、使用Vscode中SFTP插件与服务器进行文件传输</h2><h3 id="2-1-先在Vscode插件市场中，下载sftp插件"><a href="#2-1-先在Vscode插件市场中，下载sftp插件" class="headerlink" title="2.1  先在Vscode插件市场中，下载sftp插件"></a>2.1  先在Vscode插件市场中，下载sftp插件</h3><h3 id="2-2-然后在vscode中打开需要上传的本地文件或者项目"><a href="#2-2-然后在vscode中打开需要上传的本地文件或者项目" class="headerlink" title="2.2  然后在vscode中打开需要上传的本地文件或者项目"></a>2.2  然后在vscode中打开需要上传的本地文件或者项目</h3><h3 id="2-3-安装完成后，使用快捷键-ctrl-shift-p，选择-sftp-config-然后回车，会在当前目录下自动生成-vscode文件夹，并在-vscode文件夹下生成sftp-json。"><a href="#2-3-安装完成后，使用快捷键-ctrl-shift-p，选择-sftp-config-然后回车，会在当前目录下自动生成-vscode文件夹，并在-vscode文件夹下生成sftp-json。" class="headerlink" title="2.3  安装完成后，使用快捷键 ctrl + shift + p，选择 sftp:config,然后回车，会在当前目录下自动生成.vscode文件夹，并在.vscode文件夹下生成sftp.json。"></a>2.3  安装完成后，使用快捷键 <code>ctrl + shift + p</code>，选择 <code>sftp:config</code>,然后回车，会在当前目录下自动生成<code>.vscode</code>文件夹，并在<code>.vscode</code>文件夹下生成<code>sftp.json</code>。</h3><p><img src="/2025-10-14-post23_%E4%B8%8E%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%90%8C%E6%AD%A5%E7%9A%84%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/1.png"><br><strong>参数解析：</strong><br>name : 设置远端服务器名称<br>host: 远端服务器IP<br>protocol：协议类型，默认选”sftp”<br>port：端口<br>username：用户名<br>password：密码<br>remotePath：远端同步的路径</p><h3 id="2-4-配置好-sftp-json后，右键文件区点击upload即可上传文件到服务器端。-如果上传某个特定文件就直接在文件上右键，如果想全部上传，就在空白处右键-upload，建议先创建个文件夹，用于存放同步的文件。"><a href="#2-4-配置好-sftp-json后，右键文件区点击upload即可上传文件到服务器端。-如果上传某个特定文件就直接在文件上右键，如果想全部上传，就在空白处右键-upload，建议先创建个文件夹，用于存放同步的文件。" class="headerlink" title="2.4  配置好 sftp.json后，右键文件区点击upload即可上传文件到服务器端。 如果上传某个特定文件就直接在文件上右键，如果想全部上传，就在空白处右键 upload，建议先创建个文件夹，用于存放同步的文件。"></a>2.4  配置好 <code>sftp.json</code>后，右键文件区点击<code>upload</code>即可上传文件到服务器端。 如果上传某个特定文件就直接在文件上右键，如果想全部上传，就在空白处右键 <code>upload</code>，建议先创建个文件夹，用于存放同步的文件。</h3><p><img src="/2025-10-14-post23_%E4%B8%8E%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%90%8C%E6%AD%A5%E7%9A%84%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/2.png"></p><h2 id="3、使用文件传输工具进行可视化的文件传输"><a href="#3、使用文件传输工具进行可视化的文件传输" class="headerlink" title="3、使用文件传输工具进行可视化的文件传输"></a>3、使用文件传输工具进行可视化的文件传输</h2><p><strong>例如MobaXterm等可视化终端工具，支持SSH连接，同时也支持文件同步传输等功能。</strong><br><img src="/2025-10-14-post23_%E4%B8%8E%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%90%8C%E6%AD%A5%E7%9A%84%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93/3.png"></p>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 文件传输 </tag>
            
            <tag> 服务器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pyenv + poetry 进行多版本python项目管理方案</title>
      <link href="//2025-10-12-post22_pyenv+poetry%E8%BF%9B%E8%A1%8C%E5%A4%9A%E7%89%88%E6%9C%ACpython%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%96%B9%E6%A1%88/"/>
      <url>//2025-10-12-post22_pyenv+poetry%E8%BF%9B%E8%A1%8C%E5%A4%9A%E7%89%88%E6%9C%ACpython%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul><li>1、pyenv 管理不同版本的python</li><li>2、poetry根据不同的pyenv创建的python版本进行项目环境.venv的创建</li></ul><h2 id="1-使用pyenv管理不同版本的python"><a href="#1-使用pyenv管理不同版本的python" class="headerlink" title="1.使用pyenv管理不同版本的python"></a>1.使用pyenv管理不同版本的python</h2><p>对于pyenv的安装，pyenv官方github提供详细的教程，本文不再涉及，windows系统需要安装的话，可以使用pyenv-win，在github上也有仓库提供。</p><ul><li>1 查看可安装的python版本及已经安装的python版本</li></ul><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pyenv versions                 <span class="comment"># 显示已经安装的所有 Python 版本</span></span><br><span class="line">pyenv <span class="keyword">install</span> --<span class="keyword">list</span>           <span class="comment"># 显示所有可安装的 Python 版本</span></span><br></pre></td></tr></table></figure><ul><li>2.安装卸载python版本</li></ul><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pyenv install &lt;<span class="built_in">version</span>&gt;        <span class="comment"># 安装指定版本的 Python，例如 pyenv install 3.10.7</span></span><br><span class="line">pyenv uninstall &lt;<span class="built_in">version</span>&gt;      <span class="comment"># 卸载指定版本的 Python</span></span><br></pre></td></tr></table></figure><ul><li>3.设置python版本</li></ul><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pyenv <span class="built_in">global</span> &lt;<span class="built_in">version</span>&gt;         <span class="comment"># 设置全局（默认）Python 版本</span></span><br><span class="line">pyenv <span class="built_in">local</span> &lt;<span class="built_in">version</span>&gt;          <span class="comment"># 设置当前目录下的 Python 版本（写入 .python-version 文件）</span></span><br><span class="line">pyenv <span class="built_in">shell</span> &lt;<span class="built_in">version</span>&gt;          <span class="comment"># 仅当前 shell 会话使用指定版本</span></span><br></pre></td></tr></table></figure><p>以上就是基础常见的pyenv命令，pyenv作为python版本管理工具的主要作用就是管理不同版本的python，在不同的项目中，我们可能会用到不同的python版本，但是本地下载多个python版本进行切换管理非常麻烦，当然也可以使用conda进行隔离管理，但是conda比较臃肿，在开发项目中可能不是很方便，同时存在管理不同包版本依赖功能不完善的情况，可见博客<a href="https://tccjx.github.io/2025-08-24-post19_Poetry%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/">Poetry基本用法教程</a>中对此有详细的陈述。</p><h2 id="2-poetry根据不同的pyenv创建的python版本进行项目环境-venv的创建"><a href="#2-poetry根据不同的pyenv创建的python版本进行项目环境-venv的创建" class="headerlink" title="2.poetry根据不同的pyenv创建的python版本进行项目环境.venv的创建"></a>2.poetry根据不同的pyenv创建的python版本进行项目环境.venv的创建</h2><p>在第一步中，我们设置好python版本后，就可以通过poetry来创建相应的venv虚拟环境，这里建议将.venv直接设置在项目内部，建议将virtualenvs.in-project设置成true即可。</p><ul><li>1.根据系统关联的python版本创建venv环境</li></ul><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poetry <span class="keyword">env</span> use <span class="keyword">python</span>版本</span><br><span class="line">或者</span><br><span class="line">poetry shell <span class="keyword">python</span>版本</span><br></pre></td></tr></table></figure><p>这样就可以成功创建对应python版本的venv环境了。</p><ul><li>2.根据toml文件更新lock文件 并 安装相关配置环境</li></ul><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">poetry lock  <span class="comment"># then</span></span><br><span class="line">poetry <span class="keyword">install</span> </span><br></pre></td></tr></table></figure><ul><li>3.激活虚拟环境</li></ul><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">poetry <span class="keyword">env</span> use python版本号 <span class="comment"># 切换 Python 版本/解释器</span></span><br><span class="line">poetry <span class="keyword">shell</span><span class="language-bash"> (推荐)</span></span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>poetry + pyenv 的项目环境管理方式，不仅方便并且管理起来轻松，在实际开发场景中，使用得更多，并且也利用了poetry管理可复现，方便项目迭代的优点。</p>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pyenv </tag>
            
            <tag> poetry </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ssh连接远程服务器及Linux小常识</title>
      <link href="//2025-10-09-post21_ssh%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%8ALinux%E5%B0%8F%E5%B8%B8%E8%AF%86/"/>
      <url>//2025-10-09-post21_ssh%E8%BF%9E%E6%8E%A5%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%8ALinux%E5%B0%8F%E5%B8%B8%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="5049b8f4816af36b8c0ec9df3fadbd79fb2c523ed900bc109c57c6e2eb13fc96">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> private </tag>
            
            <tag> Linux </tag>
            
            <tag> Ubuntu </tag>
            
            <tag> ssh </tag>
            
            <tag> PyCharm&amp;Vscode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>综述(自用)-基于规则方法的时间知识图谱推理(预测)</title>
      <link href="//2025-09-25-post20_%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E6%97%B6%E9%97%B4%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86/"/>
      <url>//2025-09-25-post20_%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E6%97%B6%E9%97%B4%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="bb22f166eb506fef4c0dde7f1a11038b097b071b487e293fc4a40fb4643d4b45">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> private </tag>
            
            <tag> 时态知识图谱推理 </tag>
            
            <tag> 传统规则学习方法 </tag>
            
            <tag> 外推 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Poetry基本用法教程</title>
      <link href="//2025-08-24-post19_Poetry%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"/>
      <url>//2025-08-24-post19_Poetry%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1.背景"></a>1.背景</h2><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最近在复现一个项目的时候，发现项目的环境安装是使用Poetry，一脸懵逼，不知道Poetry是什么东西，以前也从来没有接触过。于是开始学习Poetry，一番了解下来，决定专门学习掌握一下Poetry这个包依赖管理工具。</p><h3 id="1-1-Poetry是什么？"><a href="#1-1-Poetry是什么？" class="headerlink" title="1.1 Poetry是什么？"></a>1.1 Poetry是什么？</h3><p>Poetry官网如此写到：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Poetry <span class="keyword">is</span> a tool <span class="keyword">for</span> dependency management <span class="keyword">and</span> packaging <span class="keyword">in</span> Python. It allows you <span class="keyword">to</span> <span class="keyword">declare</span> the libraries your project <span class="keyword">depends</span> <span class="keyword">on</span> <span class="keyword">and</span> it will manage (install/<span class="keyword">update</span>) them <span class="keyword">for</span> you. Poetry offers a lockfile <span class="keyword">to</span> ensure <span class="keyword">repeatable</span> installs, <span class="keyword">and</span> can build your project <span class="keyword">for</span> distribution.</span><br></pre></td></tr></table></figure><p>简而言之，就是一个python依赖管理工具，具有虚拟环境管理、Package依赖性管理、Package的打包与分布的功能。</p><h3 id="1-2-为什么要使用Poetry？相比pip、conda等工具他有什么优势呢？"><a href="#1-2-为什么要使用Poetry？相比pip、conda等工具他有什么优势呢？" class="headerlink" title="1.2 为什么要使用Poetry？相比pip、conda等工具他有什么优势呢？"></a>1.2 为什么要使用Poetry？相比pip、conda等工具他有什么优势呢？</h3><p>答：相比pip和conda等虚拟环境包管理工具，Poetry的优点就是其可以管理包之间的依赖的关系，比如我们安装一个包，可能这个包的使用，还需要依赖好几个其他包。pip在安装包的时候，可以将依赖的包一并进行安装，但是当我们安装完之后，我们不需要这个包的时候，我们用pip工具进行uninstall这个包的时候，由于pip无法处理依赖管理，只会uninstall指定的那个包，那么其他的依赖包就需要我们手动进行卸载，但是问题来了，如果其中某些包是好几个其他包共同依赖的包的话，这样就很容易出现依赖问题，处理起来非常棘手。<strong>Poetry的目标，就是解决pip在依赖性管理上的不足。</strong></p><p>总结: 在我们个人小项目的开发上，如果包比较少，管理起来比较方便的话，pip其实可以满足我们的需求，但是如果是大型项目，管理起来依赖就非常麻烦，如果有一些不必要的包保留下来，还会影响我们部署，浪费资源，因此使用Poetry来进行包管理工具是一件很有必要的事情。</p><h2 id="2-Poetry的安装"><a href="#2-Poetry的安装" class="headerlink" title="2.Poetry的安装"></a>2.Poetry的安装</h2><p>建议大家还是主要参考官网的教程<a href="https://python-poetry.org/">Poetry官网</a>、<br>我在ubuntu上安装的时候使用的官网推荐的official installer安装方式，并非使用pipx的安装方式，因为中科大镜像源最新版本就是2.1.3的原因，因此我安装了2.1.3,可根据自身情况指定版本号。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">curl</span> -sSL https://install.python-poetry.org | python3 - --version <span class="number">2</span>.<span class="number">1</span>.<span class="number">3</span></span><br></pre></td></tr></table></figure><p>安装完成后执行：(需要先设置环境变量)</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Poetry <span class="comment">--version</span></span><br></pre></td></tr></table></figure><p>返回版本号之后就说明安装成功。</p><h3 id="2-1-设定PATH环境变量"><a href="#2-1-设定PATH环境变量" class="headerlink" title="2.1 设定PATH环境变量"></a>2.1 设定PATH环境变量</h3><p>在linux上，设置PATH相对简单，在.bashrc 或 .zshrc后边追加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export PATH=&quot;$HOME/.local/bin:$PATH&quot;&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc </span><br></pre></td></tr></table></figure><p>windows上同样也需要设置环境变量，可以参考官网教程。</p><h2 id="3-使用Poetry生成虚拟环境"><a href="#3-使用Poetry生成虚拟环境" class="headerlink" title="3.使用Poetry生成虚拟环境"></a>3.使用Poetry生成虚拟环境</h2><h3 id="3-1-从0开始创建项目"><a href="#3-1-从0开始创建项目" class="headerlink" title="3.1 从0开始创建项目"></a>3.1 从0开始创建项目</h3><h4 id="3-1-1-初始化项目"><a href="#3-1-1-初始化项目" class="headerlink" title="3.1.1.初始化项目"></a>3.1.1.初始化项目</h4><p><strong>已创建项目使用poetry：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry init <span class="comment">#生成poetry.toml文件 </span></span><br></pre></td></tr></table></figure><p><strong>poetry初始化新建项目：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry new demo-name <span class="comment"># 创建一个完整的Poetry管理的包结构</span></span><br></pre></td></tr></table></figure><p><strong>修改config .建立项目内.venv虚拟环境</strong><br>查看poetry的配 置类型</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry <span class="built_in">config</span> <span class="comment">--list</span></span><br></pre></td></tr></table></figure><p><strong>修改为项目内建立的虚拟环境，将环境建立到当前项目中</strong></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry config virtualenvs.in-project <span class="literal">true</span></span><br></pre></td></tr></table></figure><h4 id="3-1-2-建立项目虚拟环境并使用"><a href="#3-1-2-建立项目虚拟环境并使用" class="headerlink" title="3.1.2.建立项目虚拟环境并使用"></a>3.1.2.建立项目虚拟环境并使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry env use python <span class="comment"># 创建虚拟环境并指定python版本，但是不会生成lock文件</span></span><br></pre></td></tr></table></figure><p>注： 该命令建立的虚拟环境所使用的python版本，取决于python指令在PATH中的连接的版本。</p><h4 id="3-1-3-激活poetry环境"><a href="#3-1-3-激活poetry环境" class="headerlink" title="3.1.3.激活poetry环境"></a>3.1.3.激活poetry环境</h4><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry <span class="keyword">shell</span><span class="language-bash"> 进入虚拟环境</span></span><br></pre></td></tr></table></figure><h4 id="3-1-4-添加包"><a href="#3-1-4-添加包" class="headerlink" title="3.1.4.添加包"></a>3.1.4.添加包</h4><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">poetry <span class="keyword">add</span> package-<span class="type">name</span> </span><br><span class="line">-D参数指定开发环境</span><br><span class="line"># 或</span><br><span class="line">poetry <span class="keyword">add</span> package-<span class="type">name</span> <span class="comment">--dev</span></span><br></pre></td></tr></table></figure><h4 id="3-1-5-删除包"><a href="#3-1-5-删除包" class="headerlink" title="3.1.5.删除包"></a>3.1.5.删除包</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">poetry <span class="built_in">remove</span> package-name</span><br><span class="line">-D参数指定开发环境</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除虚拟环境命令</span></span><br><span class="line">poetry env <span class="built_in">remove</span> python</span><br></pre></td></tr></table></figure><hr><h4 id="3-1-5-更新包"><a href="#3-1-5-更新包" class="headerlink" title="3.1.5 更新包"></a>3.1.5 更新包</h4><p>更新全部可以更新的包,根据poetry.toml文件中的版本限制，poetry会自动选择合适的版本进行安装，并且会更新poetry.lock文件,并且当项目没有激活或者创建虚拟环境的时候，会自动创建对应的虚拟环境。</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">poetrty update</span></span><br></pre></td></tr></table></figure><p>更新指定包</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">poetry <span class="keyword">update</span> package-<span class="type">name</span></span><br></pre></td></tr></table></figure><h4 id="Note-Important☆"><a href="#Note-Important☆" class="headerlink" title="Note(Important☆)"></a>Note(Important☆)</h4><p><strong>如果手动修改了Poetry.toml文件，需要执行以下命令，使修改生效。</strong></p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">poetry lock <span class="comment"># 将toml文件改动同步到lock文件中</span></span><br><span class="line">poetry <span class="keyword">install</span> <span class="comment"># 根据lock文件改动，拉取相关依赖到环境中</span></span><br></pre></td></tr></table></figure><hr><h3 id="3-2-在其他主机复现Poetry虚拟环境"><a href="#3-2-在其他主机复现Poetry虚拟环境" class="headerlink" title="3.2 在其他主机复现Poetry虚拟环境"></a>3.2 在其他主机复现Poetry虚拟环境</h3><p>1.git clone 项目。<br>2.此时项目中存在Poetry.toml 和 Poetry.lock文件。<br>3.poetry env use python 建立虚拟环境并使用。<br>4.poetry lock 将toml文件改动同步到lock文件中。<br>5.执行poetry install,会根据poetry.lock记录的包版本安装到虚拟环境中。</p><ul><li>poetry env list 查看虚拟环境列表 (多虚拟环境下使用，不常用)</li></ul><h3 id="3-3-如何在原项目基础上重建环境"><a href="#3-3-如何在原项目基础上重建环境" class="headerlink" title="3.3 如何在原项目基础上重建环境"></a>3.3 如何在原项目基础上重建环境</h3><p>删除.venv文件后，直接执行’poetry env use python’,但是这个应该用的会很少</p><h2 id="4-常用命令（使用export插件导出requirement-txt方法）"><a href="#4-常用命令（使用export插件导出requirement-txt方法）" class="headerlink" title="4.常用命令（使用export插件导出requirement.txt方法）"></a>4.常用命令（使用export插件导出requirement.txt方法）</h2><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">一、poetry shell插件</span><br><span class="line"><span class="keyword">from</span> poetry2<span class="number">.0</span>起，shell命令不再是默认安装的了。</span><br><span class="line">poetry shell插件安装查看: https://github.com/python-poetry/poetry-plugin-shell</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">二、基本常用命令作用</span><br><span class="line"><span class="number">1.</span>env activate: Print the command <span class="keyword">to</span> activate a virtual environment.</span><br><span class="line"><span class="number">2.</span>env <span class="keyword">info</span>: Displays information about the <span class="keyword">current</span> environment.</span><br><span class="line"><span class="number">3.</span>env list: Lists <span class="keyword">all</span> virtualenvs associated <span class="keyword">with</span> the <span class="keyword">current</span> project.</span><br><span class="line"><span class="number">4.</span>env remove: Remove virtual environments associated <span class="keyword">with</span> the project.</span><br><span class="line"><span class="number">5.</span>env use: Activates <span class="keyword">or</span> creates a <span class="built_in">new</span> virtualenv <span class="keyword">for</span> the <span class="keyword">current</span> project.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">1.</span>更新命令 </span><br><span class="line">poetry <span class="keyword">lock</span> </span><br><span class="line">依据 poetry.toml 来更新 poetry.<span class="keyword">lock</span></span><br><span class="line">但是仅仅会更新poetry.<span class="keyword">lock</span>，而不会安装相关依赖</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>根据poetry.<span class="keyword">lock</span>安装相关依赖包</span><br><span class="line">poetry install</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span>Poetry更新套件(一般不使用)</span><br><span class="line">poetry <span class="keyword">update</span>: 更新全部套件</span><br><span class="line">poetry <span class="keyword">update</span> requests toml 更新指定的某个套件</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span>poetry <span class="keyword">show</span></span><br><span class="line">展示环境包内容，环境不是来自虚拟环境，而是根据poetry.<span class="keyword">lock</span>文件来展示的。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span>poetry <span class="keyword">show</span> <span class="comment">--tree(包之间的依赖关系与层次，一目了然)</span></span><br><span class="line">展示环境依赖树状结构</span><br><span class="line"></span><br><span class="line"><span class="number">6.</span>移除命令</span><br><span class="line">poetry remove package-<span class="type">name</span></span><br><span class="line"></span><br><span class="line"><span class="number">7.</span>退出poetry环境</span><br><span class="line"><span class="keyword">exit</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">三、export插件导出requirements.txt文件 (导出requirements.txt文件)</span><br><span class="line">**输出requirements.txt(<span class="number">2.0</span>版本以后)**</span><br><span class="line">poetry export -f requirements.txt -o requirements.txt <span class="comment">--without-hashes</span></span><br><span class="line">export插件地址：https://github.com/python-poetry/poetry-plugin-export</span><br><span class="line">使用方法：</span><br><span class="line">在Poetry2<span class="number">.0</span>及以上版本，直接在poetry.toml中声明如下：</span><br><span class="line">[tool.poetry.requires-plugins]</span><br><span class="line">poetry-plugin-export = &quot;&gt;=1.8&quot;</span><br><span class="line"></span><br><span class="line">或者 </span><br><span class="line"></span><br><span class="line">poetry self <span class="keyword">add</span> poetry-plugin-export(未尝试)</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>花了半天时间吧，基本掌握了poetry工具的使用，总体来说还是很方便的，但是学习起来相比pip等工具还是有一定的门槛，不过比起这个，可以解决掉环境包依赖的问题，还是很好，有利于项目的复现！</p><h2 id="使用场景QA"><a href="#使用场景QA" class="headerlink" title="使用场景QA"></a>使用场景QA</h2><h3 id="1、新建项目"><a href="#1、新建项目" class="headerlink" title="1、新建项目"></a>1、新建项目</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>poetry init <span class="comment"># 生成poetry.toml文件及设置相关依赖包</span></span><br><span class="line"><span class="number">2.</span>poetry env use 指定python版本</span><br><span class="line"><span class="number">3.</span>poetry lock &amp; poetry install </span><br><span class="line"><span class="comment"># poetry check # 检查项目依赖关系，如果依赖关系有错误，则会报错</span></span><br><span class="line"><span class="number">4.</span>poetry shell <span class="comment"># 如未执行步骤2，则会自动建立相应的虚拟环境</span></span><br><span class="line"><span class="number">5.</span>poetry add package-name</span><br><span class="line"><span class="number">6.</span>poetry remove package-name</span><br></pre></td></tr></table></figure><h3 id="2、现有项目改用Poetry进行管理"><a href="#2、现有项目改用Poetry进行管理" class="headerlink" title="2、现有项目改用Poetry进行管理"></a>2、现有项目改用Poetry进行管理</h3><p>最好的办法还是重新使用poetry进行管理，避免不必要的麻烦</p><h3 id="3、在其他开发环境上复现-Poetry虚拟环境"><a href="#3、在其他开发环境上复现-Poetry虚拟环境" class="headerlink" title="3、在其他开发环境上复现 Poetry虚拟环境"></a>3、在其他开发环境上复现 Poetry虚拟环境</h3><p>1.git clone 项目<br>2.项目中存在Poetry.toml 和 Poetry.lock文件<br>3.poetry env use python 建立虚拟环境并使用。 # 该命令仅仅是为当前项目选择或创建虚拟环境<br>4.执行poetry install,会根据poetry.lock记录的包版本安装到虚拟环境中</p><h3 id="4、在原项目基础上重建环境"><a href="#4、在原项目基础上重建环境" class="headerlink" title="4、在原项目基础上重建环境"></a>4、在原项目基础上重建环境</h3><p>删除.venv文件后，直接执行’poetry env use python’或’poetry shell’建立一个新的即可。</p><h3 id="5、Poetry设置国内源"><a href="#5、Poetry设置国内源" class="headerlink" title="5、Poetry设置国内源"></a>5、Poetry设置国内源</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加镜像源，默认就是主要源，注意该方式只对当前项目有效</span></span><br><span class="line"><span class="comment"># 命令格式：poetry source add [选项] [--] &lt;name&gt; [&lt;url&gt;]，name：源仓库的名称，url：源仓库的 URL</span></span><br><span class="line">$ poetry source add tsinghua https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">Adding source <span class="keyword">with</span> name tsinghua.</span><br><span class="line"></span><br><span class="line"><span class="comment"># --priority=PRIORITY设置此源的优先级。可以是以下值之一：default（默认）、primary（主要）、supplemental（备用）、explicit（显式源，只有当包明确声明使用该源时才会被使用）。默认为 primary。</span></span><br><span class="line">$ poetry source add  --priority=supplemental aliyun http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看镜像源信息</span></span><br><span class="line">$ poetry source show</span><br><span class="line"> name      : tsinghua</span><br><span class="line"> url       : https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"> priority  : primary</span><br><span class="line"></span><br><span class="line"> name      : aliyun</span><br><span class="line"> url       : http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line"> priority  : supplemental</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此时查看 pyproject.toml 文件可以看到镜像源信息</span></span><br><span class="line">[[tool.poetry.source]]</span><br><span class="line">name = <span class="string">&quot;tsinghua&quot;</span></span><br><span class="line">url = <span class="string">&quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;</span></span><br><span class="line">priority = <span class="string">&quot;primary&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[[tool.poetry.source]]</span><br><span class="line">name = <span class="string">&quot;aliyun&quot;</span></span><br><span class="line">url = <span class="string">&quot;http://mirrors.aliyun.com/pypi/simple/&quot;</span></span><br><span class="line">priority = <span class="string">&quot;supplemental&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除镜像源</span></span><br><span class="line">$ poetry source remove aliyun <span class="comment"># 指定镜像源名称</span></span><br><span class="line">Removing source <span class="keyword">with</span> name aliyun.</span><br></pre></td></tr></table></figure><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p><a href="https://blog.hanqunfeng.com/2024/11/22/python_poetry/?highlight=poetry">更详细的参考博客</a></p>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Poetry </tag>
            
            <tag> pip </tag>
            
            <tag> python环境管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读笔记---LCGE-基于逻辑和常识来实现时态知识图谱补全的方法</title>
      <link href="//2025-08-16-post18_LCGE-%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%92%8C%E5%B8%B8%E8%AF%86%E7%9A%84%E6%97%B6%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86%E8%A1%A5%E5%85%A8%E6%A8%A1%E5%9E%8B/"/>
      <url>//2025-08-16-post18_LCGE-%E5%9F%BA%E4%BA%8E%E9%80%BB%E8%BE%91%E5%92%8C%E5%B8%B8%E8%AF%86%E7%9A%84%E6%97%B6%E6%80%81%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86%E8%A1%A5%E5%85%A8%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="e20b3a5e18b7410ab0ecc476026297ddb359ac05b4f0698674ef9a3e553de6fe">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> private </tag>
            
            <tag> 传统规则学习方法 </tag>
            
            <tag> 时态知识图谱补全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读笔记---LLM结合规则学习方法提出一种新的时态知识图谱推理框架</title>
      <link href="//2025-08-11-post17_GenTKG-%E4%BC%A0%E7%BB%9F%E8%A7%84%E5%88%99%E6%96%B9%E6%B3%95%E7%BB%93%E5%90%88%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/"/>
      <url>//2025-08-11-post17_GenTKG-%E4%BC%A0%E7%BB%9F%E8%A7%84%E5%88%99%E6%96%B9%E6%B3%95%E7%BB%93%E5%90%88%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="fe150fecd42ca5f24d3d63c1461f57dc6f9ee8d9206db797197b1af9185873e0">3f1e03392662fec3a76791e572a1a763449dd38850f70b89d0ca4eb307ae20ab5020b55f7632b8afdae26a61ccced3c3a6d32cb5a58ee4ca833ece6b677f5f85a2121eae40ad3d19985e275d484e8bd0de56cbe9269bbd51ddf6d7477062d144cfe429b3ad80de6c1851a86be2bb4f52700a9cc4ca5a8cd92b5c69b2724223e39efb0eb711fc6cb402d2f49671bf826563e81e0bd4e55bf8c895acd78dc8f631bcd867fe301e91904e37db56e7d4ebed371fdc31d5edefdbf5ba1a1ab2e351071b6ac72fa7dbbbcacdbad1a94759f3d24c2081d519d34397e70d744824d01b38ba22e5c160e53ad62de1a535125cf43b97f2d83b72fd9f7a6ac90ec5a6c1a57639bb2dc775ed37861e4c5c8d92a454400b73610a13a6c8964d02ee6ba94b2358229381e21006e22bf49ef4d16c87ef5772d11715f313a6a2beef13ab445a296035d32c50ef7ab07aa2e4af0f7a516d6b13c08ab04307beb82ef9e81135739be2ebe18783961db99d7612c332c978681405b76a18a4cb9adc29c88697cd56fe05674dfb38381c1b79e6c63b5bb1b5105ff230bf1ef1995d90c517d79fa43d2920223e2fde5595696fea37e3d13452ec4fd0dc850706b7e3f1ad573a02700d57eafebdb4cd5f6da7c4cb128bfeb541027cccd1f4339db89c854dc37803971389ef88867a062d2c421035f0e36e549db115f67901c5032e7a0c37cb16829f7a7614a02b3e88627bbb18d63ba13d59a0320da2694b7526732b2154230d2bceba71421947a14efd16a137dc4f91d32e9d34544cc66a1202c05a25def3cd7bb995374abc4f6c60c9361eb84d6b47ca4290f557a6cebd9fd8d1e68513bae27a38f830db10cc6e17f61b4dbbdc0f26b05784448b3b89bca9464386449add736758989b3c61567c593adfc52068084ae250bfd84cb1c25a139a2716df2c8cfa61d8ba7c644cc8436bdd9505b670f954229ca04e01f4e11011501997b290b05c2760c1c7bb18bb606753f13cb1835d5ad0c7291865175813b620b6cb775962f80c4638c18495065bc3f17495a47f14a3679bfc388449df30951bd440dbfcc39f619f2f6687da2670bc8423718b20aa37abebed819c41a1f507cd749445d9b95aa07df68b46b62cc3ea39710ba93dc6295f3c2db8fef16a49fe8dac5b5dc1bfdd0aaa135f65e1b93e307cd86a0c20c382cf73c0b8bb128a650f5b8fbe22d6b764097ee74a6c1e4f68f54b7c055f7e5365e90dafbe54c19b6efc365ee862ee01317d1ad9083b6a1dfbf0279905b2ca9549a364a788614d0ff55dbc5cef6070a102aac485fa474ff637b25d340ffce3e2f459437e6cafa4162c726fc05168b799e5d20f773ab1cee611b182a1105da9532fc64163d09adc949715979ec8112f334c052c00acbcd3f060b42f93f201e53d22c6123c51e77ab5b9299f6b724e43dd844ccce218f0b8a352fa9002a19ac6af18d08dbfbfd6fcef79243dcef393984b17a84d2b86b78cecc6f90061424a566c12b7bcb40c239cad493545244c88e556a5a44db9136a628089486d6fd8d5d39183de6dea5b4c05d9c9ae863aa701f0c642eda614d6e29ad3da690af1f309452caaf080a5a25e661048fa9c73a9fd7587c9bbfd624b4b968807f656942226d99ddd3c2e7b9d41bad851aeec8b17003c620b5d4463be3d5ddccf71345d77b67b52219765a8ba3dadd5c5892ed495788818a9a1d072777aea874907f108a7c3e3d32f8fd3f06e5ae230d5fd11f4d2d25ee10773107478563651dc699bde81400ebdfef5ff8a4e59586e21e6e560f1cff13539f9efc0b0607a2fb89e711a55ebd96fe216849b0f8ac633a6461050a9c1c27f1a24eb275f36219193f051ffb35e8cdea0a5078d6e4946c128e5b8fd709430027057a2f9737d814a110050f194006d85802a9bb7a0d16f37622fd3e54a7a6fb0284474a9c12ad31022532a434387b7344ff8b00d54e31e91aec582f27f61eb47ef0c2ddef357d13a70395156c166e1ca5f3a341adbc9b3f3c375c2d19c337529fec2175313f66793aa00df97a4ae02124fe01ca039178f669f895ea606a4b2067621f7a01501e67e500a7f7adbed3e67f23fb64b2c7833c6cb3cb8d6ae1456049dcfcbd0addd0535e5564dc1daac7c7d26214594efcc38a33487a85ecffdd59d45baf64e5a05990e4b6fed81a13e78ac21e85c4379aead15c0fd530974a325df422227ff22f07eaf8842fdc195f917177058bd5ea9035d593d647b824e38b7313a08ff45ada7eecc1bebbf80e61c9161e5cc939e0a9e04b8587504bd30f1fff32467db581e8331cac4d80d48c7740e36825abc3333aeaf3ea11d95c5e7814157f5979ba91a939f0e8a3979b8f59ce3a92a2623456c0ffdaf104853fb5b402e1a054a534e24555d8f9cec523800e2cb4f8ecfe2f790e75a63163d62bb8f0286fe6df2854f3790334864d481404f19ef9fc0b643971c20c4e2fe5e30a910d3b6b218310f9ea2fff78b31e8db83c510534e1d3bdb31b3d3bea687f2b7fcd6041c5ea3a8552b80bb1d5909109de11635e82673b977c804a8d73510cfae2dcd25f5168dd34bcdeb6251ec2d185292ce52c05cf65b5da16ebfdfff6b5f998027d2463c7a1343617a6a5c40d425b629e5f71e24993f1a01a59567edfb2685f49ea3904da24cba0b64ef531846136adbb57b44441f1eb7ad481496772ba0b9bc89fd3fd33fdb42c1c6dd3247530df9f21056efa60890f4379f38d7a9e0831214ad058fb7a2addaca845be9f886ac93cf88af528d30d39d5cd0445891b0da48abcfed82592068a1eb5f7140517fe03960e9d83d6680afb485539386ee1ae431d0d72adb91bb272092139e00dabf93db4531302e8a2bc5859f3764d6840e9dba3fe6edb89826658d08c23066cde9198b542f01a2c7adb0b8c428aec5c61ecb4fbe2146348c6de8e9f8290113ae24f28dde5cef7f7c80e42b57bbe5b6515abca81ae7d23fab3452b55bd1052756576132ce6775366ffe73f678c51ad5b42f576c0c64f8eafbcfbc5b602c1b88aed471d167aa3b1e72ef9f40f6ed4bb5799487a15c7debb4b93a30b643dda3aeb5643c86a6c5fedd3b90d0915b1e1f1fffc56d0f028263915c164341cd79ba79bc130ee3f89b9d52db5d437925882266347a9398d7839e0ec9e6c9fcda6cf5f5265927f837b3b6862a69808b6ebb1ebc94ab5c7973a3451879f24d26d125db2ccfca0fec12ab15d721b2d47a61ebd305632711f83f88f1718d5ac0aca17d1103013a7d60f1aa420aeefef262ee41952969df2c3a71e74b759f677320d4acdd218ffb263f53eafb410c8713dce56050ce0074f471516ed6a25cb41b5dd3e79934bef63b27fccb0f2169a0b7b7959117dff586fa4a06fcb726938a5df83c608ae4c0fa4074c2f13e841c97a6c9ed1659f2337fa4efde99098d3d9e955e5afc9c3379eebbb33a7ad15599b4950d46c43c16a09c6edaa3ea77ae00c86df08d771fbad55029be40a004395a57fe731498be67053f076db7e9e6801a029f0de292985179a1bf58437b1dbf685ec5077de0d7675213e968b8f00c138fc18617d1ef56a1eb340a63bf62320bd1693117dbe3cdd3d59408e12f26be9b63550f609f502754ac592f905276c57f31d6ef900c62df9cda0910d2d957d2e03dc0dce198f45e6b764266290bb0bc3397154db200198c9f3b090014a0ee0deb65f5427c1532d4840c76ed29ce494da53fbba0272b060c16c766e61e5a74dd2b17885cb7dee1b0bbd3a9d8778a32d6cd0bcba39fffe3a51280f6298628385ab85cc5014eb0df8fa5f515cd23f5bb1ce3d5591553ba726b55c1d5d30bb3c7b213ea7a579894cb09dbc614a2252393b079d1132c3c7b28eaeee5094e22721689aa6e30f29797174f4004ea402633786be4475f078cdd79794e7b0ae5ee91a42e90fc699753dad748fdc0f56920fee66507b3acd49632ca496375cb7265ae7073809c4e08233a416a1e59a4429451a787d2c4e0dd9e09b23b99be0566e5abd3a749c1e29379845012c80eebc655addf8dd7f06f056ea2b76defa13b2e630adfd1637d114871538632e15ac42ef7b5e871de0e7b1af5b4df25fb21180754c2666bd415730413137ff27e6500f7c4a89b9ac3fb312f16170c1cbd4ab3b43260c87272bba69d9067c7171e61af37eda1f0ec6f1eddd520b2c25d428bc1ef16603a94feba2a4828e91876576c04a6df081ec020beabbd36aee178e506dc60ae49c8811f4b375fb6cb3294aa3f38396e1ad97901ce5414dc72dbaccccb2f49d62fa19f45e904df825baee6b4ac368a0a6e29d843fe68fa32539bbff79bd35fd64eeefd6352559718318adf20b7c96566086ba77db0a4341f79a40d496d8bdee56d7e6c05ab708791b053b12a97c8138f8869c4af40e5c2d97b00ff1bcf969542ce2b26903e9bd89bfb39be8793382e0cc29705bfe5790dc08f9878e168edef16f0d8a2d5f92b111591d5b7565ed7aa5eee24034e2f09c76d4bd78cb7f4c1c7cfba55185b2ce455d706df4694d46cf1d86dd291f8c26ddb7da4e8c7d8f725117532e24b8e79e30623282c56ccda69559479e0db0bebe1a730287d98407f35853d56e1283fd061ed931d9b257e7bb683f7f75fe3f0bae7b96375b6051b38037a52913919a9b4d969e496402ca8cee0fa33613fb64a68b874ef6d22ddc7938ccfc1d0a8952e8ed61edcb09177aaf6a0c7f35d7dabf9e371346bd8b362fcc3d14789424e53230cb729e5911880e76682294a1555cb2efe861305b012e7b6b44711963416570949d13cc30e8afb5186d1e7e98fdf4f76e129bf8658d45eb718fd6f3ca3e76ab5cbbd09f7702ee153bf4c91741be3fce4ef7ec2ffb82ab5cbdcafc6751834cd0219f095786d6c08b5ae1da9659ed8f5ab7b197e578de719da6d3f10d7983395ea14f5c66f33aea0b35c78680e71412f4aeb18514c4e68ecc04935d445d498137007fc58be1d147b03b83c93ebcd55f7a678a3be84f03ad44467452c66efa7ada68a990cd8580652acb25d6aa9df18bf006f63f2c82146d2aa4fa4e1a33cfdcd3dba82d775604e80ff3d8a87b5eaabc628307cb4858c05afd94f67141e986e73d7009753d06b888db8a86ebf881d5f3cb6505d534eea6b6b454a587bc9c83a00568fdf60fb50b94363edd2ced4eb62ec8d956a6d5b9eef50de47374c433ed9d9fb780b2a263875851ce0f590f6b2909e03f1a6a8ff06cbc97d9e0c0132d9d2590fa2f97d784f2a766f3be5d98567a16c50a76252a2e48ff33bb3d691fc62a7cd9127984d568cc8c6de479bddba5b28e8f3ec99027d8897c4d888345353fb0c6c42bb89b61a0c98359662b65665a4a4bbddfc2ae14d94de0543408b6cd30823391911ec1e1cd455a8</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
            <tag> private </tag>
            
            <tag> 时态知识图谱推理 </tag>
            
            <tag> 传统规则学习方法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>损失函数中的温度参数τ</title>
      <link href="//2025-07-15-post16_%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%AD%E7%9A%84%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%CF%84/"/>
      <url>//2025-07-15-post16_%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%AD%E7%9A%84%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%CF%84/</url>
      
        <content type="html"><![CDATA[<p>在对比学习的损失函数（如InfoNCE、NT-Xent等）中，<strong>温度参数（Temperature，通常用τ表示）</strong> 是一个核心超参数，其核心作用是<strong>调节模型对样本间相似度差异的敏感程度</strong>，通过缩放相似度分数来控制损失函数中正负例的区分强度。</p><h3 id="1-温度参数的数学位置"><a href="#1-温度参数的数学位置" class="headerlink" title="1. 温度参数的数学位置"></a>1. 温度参数的数学位置</h3><p>以最常用的InfoNCE损失为例，其公式可简化为：<br>$$\mathcal{L} &#x3D; -\log\left( \frac{\exp(\text{sim}(z_i, z_+)&#x2F;\tau)}{\sum_{k \in \text{neg} \cup {+}} \exp(\text{sim}(z_i, z_k)&#x2F;\tau)} \right)$$<br>其中：  </p><ul><li>$z_i$ 是锚点样本的特征向量，$z_+$ 是正例样本的特征向量，$z_k$ 是负例样本的特征向量；  </li><li>$\text{sim}(\cdot, \cdot)$ 是相似度函数（如内积、余弦相似度)，一般都是余弦相似度；</li><li>$\tau$ 即为温度参数，位于指数函数的分母，作为softmax的缩放因子。</li></ul><h3 id="2-温度参数的直观含义"><a href="#2-温度参数的直观含义" class="headerlink" title="2. 温度参数的直观含义"></a>2. 温度参数的直观含义</h3><p>温度参数的核心作用是<strong>调节相似度分布的“尖锐度”</strong>，控制模型对正负例相似度差异的敏感程度，具体表现为：  </p><h4 id="（1）低温（τ-→-0）：强化差异敏感性"><a href="#（1）低温（τ-→-0）：强化差异敏感性" class="headerlink" title="（1）低温（τ → 0）：强化差异敏感性"></a>（1）低温（τ → 0）：强化差异敏感性</h4><p>当τ很小时，$\exp(\text{sim}&#x2F;\tau)$ 对相似度的微小差异会极其敏感：  </p><ul><li>若正例与锚点的相似度（$\text{sim}(z_i, z_+)$）显著高于所有负例，分子会远大于分母中的负例项，softmax输出趋近于1，损失趋近于0（模型“轻松”区分）；  </li><li>若存在负例与锚点的相似度接近正例（即“难负例”），分子与分母的差距会被放大，softmax输出趋近于0，损失会急剧增大（模型被强制“重视”并修正这种模糊性）。</li></ul><p>此时，模型会被强制学习<strong>更陡峭的决策边界</strong>，对正负例的区分要求极严格，但可能因过度关注细节而导致过拟合。  </p><h4 id="（2）高温（τ-→-∞）：弱化差异敏感性"><a href="#（2）高温（τ-→-∞）：弱化差异敏感性" class="headerlink" title="（2）高温（τ → ∞）：弱化差异敏感性"></a>（2）高温（τ → ∞）：弱化差异敏感性</h4><p>当τ很大时，$\exp(\text{sim}&#x2F;\tau)$ 对相似度的差异不敏感，所有项的指数值接近1，softmax分布会更“平缓”：  </p><ul><li>正例与负例的相似度差异被缩小，模型对“难负例”的惩罚减轻；  </li><li>损失函数的梯度更平缓，模型学习更“保守”，可能导致特征区分度不足。</li></ul><p>此时，模型更关注<strong>全局分布的一致性</strong>，但可能因区分度过低而学习效果下降。  </p><h4 id="（3）总结：温度的“调节”作用"><a href="#（3）总结：温度的“调节”作用" class="headerlink" title="（3）总结：温度的“调节”作用"></a>（3）总结：温度的“调节”作用</h4><p>温度参数本质是<strong>平衡正负例的区分强度与模型鲁棒性</strong>的旋钮：  </p><ul><li>较小的τ增强对差异的敏感度，适合需要精细区分的任务（如细粒度分类）；  </li><li>较大的τ降低敏感度，适合噪声较多或负例质量参差不齐的场景（如大规模无标注数据）。</li></ul><h3 id="3-实际应用中的特点"><a href="#3-实际应用中的特点" class="headerlink" title="3. 实际应用中的特点"></a>3. 实际应用中的特点</h3><ul><li><strong>超参数属性</strong>：温度参数通常需要通过网格搜索或经验调参确定（如视觉领域常用τ&#x3D;0.07，NLP领域可能因任务不同调整）；  </li><li><strong>与任务强相关</strong>：最优τ值依赖于数据集规模、正负例质量、相似度函数等，无统一标准；  </li><li><strong>类比来源</strong>：命名借鉴了统计力学中的“温度”概念——低温下粒子运动更集中（分布尖锐），高温下更分散（分布平缓）。</li></ul><p>综上，温度参数是对比学习中控制特征区分度与鲁棒性的关键超参数，通过调节相似度分布的尖锐度，直接影响模型对正负例差异的学习强度。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 对比学习 </tag>
            
            <tag> contrastive learning </tag>
            
            <tag> 温度参数τ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>什么是glue code？</title>
      <link href="//2025-07-09-post15_glue_code/"/>
      <url>//2025-07-09-post15_glue_code/</url>
      
        <content type="html"><![CDATA[<h2 id="科普向：什么是胶水代码？为什么胶水代码不需要修改实质性逻辑？"><a href="#科普向：什么是胶水代码？为什么胶水代码不需要修改实质性逻辑？" class="headerlink" title="科普向：什么是胶水代码？为什么胶水代码不需要修改实质性逻辑？"></a>科普向：什么是胶水代码？为什么胶水代码不需要修改实质性逻辑？</h2><p><strong>Glue code</strong>（胶水代码）是指用于把不同的软件组件、库、系统或模块“粘合”在一起，使它们能够协同工作的代码。它通常本身不是实现业务逻辑的核心部分，而是负责不同部分之间的对接、适配和调用。</p><h3 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h3><ul><li><strong>桥梁作用</strong>：连接两个或多个原本不兼容或相互独立的系统、库或模块。</li><li><strong>适配&#x2F;转换</strong>：可能包括参数格式转换、接口适配、协议兼容等。</li><li><strong>非核心逻辑</strong>：不直接实现业务目标，而是保证各部分能正常协同。</li><li><strong>常见于集成开发</strong>：如将第三方库集成到自己的项目、跨语言模块通信等场景。</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><ol><li><p><strong>API包装器</strong><br>比如，用 Python 写一段代码，把 C 语言的库通过 ctypes&#x2F;cffi 调用起来，这部分代码就是 glue code。</p></li><li><p><strong>数据转换</strong><br>在前端和后端之间传递数据时，把后端的 JSON 数据转成前端可用的对象，这个转换代码也可以视作 glue code。</p></li><li><p><strong>中间件</strong><br>在微服务架构中，不同服务通过中间件（如消息队列、API 网关）交互，中间件的适配代码也可称为 glue code。</p></li></ol><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ul><li>降低不同技术栈、语言、平台之间的集成难度。</li><li>提高现有组件复用，减少重复造轮子。</li><li>能让各部分独立开发、演进。</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>可能增加系统复杂度，难以维护。</li><li>过多的 glue code 可能掩盖架构问题。</li></ul><p><strong>总结：</strong><br>Glue code 就像软件世界的“接口适配器”或“管道工”，能让各自工作的部分顺利衔接起来。</p>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> glue code </tag>
            
            <tag> 胶水代码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时态知识图谱外推任务指标计算中过滤策略选择问题</title>
      <link href="//2025-06-21-post14/"/>
      <url>//2025-06-21-post14/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="011820ac3d54380dbe531eb85444917d0bf69e6344f64116101807d0ded549ef">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> private </tag>
            
            <tag> 时态知识图谱 </tag>
            
            <tag> 图谱推理任务 </tag>
            
            <tag> MRR </tag>
            
            <tag> Hit@1&#92;3&#92;5&#92;10 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python脚本传入参数</title>
      <link href="//2025-06-19-post13_python%E8%84%9A%E6%9C%AC%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0/"/>
      <url>//2025-06-19-post13_python%E8%84%9A%E6%9C%AC%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>&ensp;&ensp;&ensp;&ensp;在日常使用一些数据处理脚本以及训练模型的时候，使用传递参数很常见，因此对使用python进行参数传递的方式进行了整理</p><h3 id="1-使用sys-argv的数组进行传参"><a href="#1-使用sys-argv的数组进行传参" class="headerlink" title="1.使用sys.argv的数组进行传参"></a>1.使用sys.argv的数组进行传参</h3><p>使用sys.argv必须按照先后的顺序传入对应的参数；sys.argv则封装了传入的参数数据，作为数组的方式进行传入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;传入参数：&#x27;</span>, sys.argv)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;传入参数的总长度为：&quot;</span>, <span class="built_in">len</span>(sys.argv))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;type:&quot;</span>, <span class="built_in">type</span>(sys.argv))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;function name:&quot;</span>, sys.argv[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第一个传入的参数为:&quot;</span>, sys.argv[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第二个传入的参数为:&quot;</span>, sys.argv[<span class="number">2</span>])</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Input Error:&quot;</span>, e)</span><br></pre></td></tr></table></figure><p><strong>运行的output:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">传入参数： [<span class="string">&#x27;py_test.py&#x27;</span>, <span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>]</span><br><span class="line">传入参数的总长度为： <span class="number">3</span></span><br><span class="line"><span class="built_in">type</span>: &lt;<span class="keyword">class</span> <span class="string">&#x27;list&#x27;</span>&gt;</span><br><span class="line">function name: py_test.py</span><br><span class="line">第一个传入的参数为: one</span><br><span class="line">第二个传入的参数为: two</span><br></pre></td></tr></table></figure><h3 id="2-使用argparse包传入"><a href="#2-使用argparse包传入" class="headerlink" title="2.使用argparse包传入"></a>2.使用argparse包传入</h3><p>args.add_argument的方法的type参数理论上可以是任何合法的类型，而且传入的顺序没有要求，这点来说比较方便，因此在现在脚本的编写上，使用argparse包越来越常见。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line">args = argparse.ArgumentParser(description=<span class="string">&#x27;argparse testing&#x27;</span>)</span><br><span class="line">args.add_argument(<span class="string">&#x27;--name&#x27;</span>,<span class="string">&#x27;-n&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default = <span class="string">&quot;bk&quot;</span>,required=<span class="literal">True</span>,<span class="built_in">help</span>=<span class="string">&quot;a programmer&#x27;s name&quot;</span>)</span><br><span class="line">args.add_argument(<span class="string">&#x27;--age&#x27;</span>,<span class="string">&#x27;-a&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">35</span>,<span class="built_in">help</span>=<span class="string">&#x27;age of the programmer&#x27;</span>)</span><br><span class="line">args.add_argument(<span class="string">&#x27;--sex&#x27;</span>,<span class="string">&#x27;-s&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;male&#x27;</span>)</span><br><span class="line">args.add_argument(<span class="string">&#x27;--favorite&#x27;</span>,<span class="string">&#x27;-f&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>, nargs=<span class="string">&quot;+&quot;</span>,required=<span class="literal">False</span>,<span class="built_in">help</span>=<span class="string">&quot;favorite of the programmer&quot;</span>)</span><br><span class="line">args = args.parse_args() <span class="comment"># !解析命令行参数并将参数保存在args中</span></span><br><span class="line"><span class="built_in">print</span>(args.name)</span><br><span class="line"><span class="built_in">print</span>(args.age)</span><br><span class="line"><span class="built_in">print</span>(args.sex)</span><br><span class="line"><span class="built_in">print</span>(args.favorite)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注： nargs参数的作用是指定需要接收的参数数量</span></span><br><span class="line"><span class="literal">None</span>：表示只接收一个参数</span><br><span class="line">N(整数)： 表示必须接收正好N个值</span><br><span class="line"><span class="string">&#x27;?&#x27;</span>： 表示可选一个值，如果没有值则使用默认参数</span><br><span class="line"><span class="string">&#x27;*&#x27;</span>： 表示可以接收零个或多个值，所有值被收集成一个列表</span><br><span class="line"><span class="string">&#x27;+&#x27;</span>: 表示必须有一个或多个值，至少有一个，结果为列表</span><br></pre></td></tr></table></figure><h3 id="3-通过shell脚本的形式进行传参"><a href="#3-通过shell脚本的形式进行传参" class="headerlink" title="3.通过shell脚本的形式进行传参"></a>3.通过shell脚本的形式进行传参</h3><h4 id="3-1-使用shell脚本向python脚本进行传参"><a href="#3-1-使用shell脚本向python脚本进行传参" class="headerlink" title="3.1 使用shell脚本向python脚本进行传参"></a>3.1 使用shell脚本向python脚本进行传参</h4><p>python 脚本依旧使用sys.argv的数组方式进行传入。</p><p>python文件:py_test.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;传入参数的总长度为：&quot;</span>, <span class="built_in">len</span>(sys.argv))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;type:&quot;</span>, <span class="built_in">type</span>(sys.argv))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;function name:&quot;</span>, sys.argv[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第一个传入的参数为:&quot;</span>, sys.argv[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;第二个传入的参数为:&quot;</span>, sys.argv[<span class="number">2</span>])</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Input Error:&quot;</span>, e)</span><br></pre></td></tr></table></figure><p>shell脚本文件：py_test_shell.sh</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义变量</span></span><br><span class="line">para1=$</span><br><span class="line">1para2=$2</span><br><span class="line">python python_test.py $para1 $para2</span><br></pre></td></tr></table></figure><p>终端执行命令：sh py_test_shell.sh test01 test02</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">传入参数的总长度为： <span class="number">3</span></span><br><span class="line"><span class="built_in">type</span>: &lt;<span class="keyword">class</span> <span class="string">&#x27;list&#x27;</span>&gt;</span><br><span class="line">function name: py_test.py</span><br><span class="line">第一个传入的参数为: test01</span><br><span class="line">第二个传入的参数为: test02</span><br></pre></td></tr></table></figure><h4 id="3-2-使用shell脚本向python脚本内的方法传递参数"><a href="#3-2-使用shell脚本向python脚本内的方法传递参数" class="headerlink" title="3.2 使用shell脚本向python脚本内的方法传递参数"></a>3.2 使用shell脚本向python脚本内的方法传递参数</h4><p>python脚本如下：(py_test.py)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fun1</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;无参数方法fun1&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun2</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;有参数方法fun2且传入的参数为<span class="subst">&#123;x&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure><h5 id="3-2-1-1-无参数调用："><a href="#3-2-1-1-无参数调用：" class="headerlink" title="3.2.1 (1)无参数调用："></a>3.2.1 (1)无参数调用：</h5><p>文件名：py_test_shell.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#定义变量</span></span><br><span class="line">python -c <span class="string">&#x27;import python_test;print(python_test.fun1())&#x27;</span></span><br></pre></td></tr></table></figure><p>sh py_test_shell.sh<br>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">无参数方法fun1</span><br></pre></td></tr></table></figure><h5 id="3-2-2-2-有参数调用："><a href="#3-2-2-2-有参数调用：" class="headerlink" title="3.2.2 (2)有参数调用："></a>3.2.2 (2)有参数调用：</h5><p>文件名：py_test_shell.sh</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#定义变量</span></span><br><span class="line">para=$<span class="number">1</span></span><br><span class="line">python -c <span class="string">&quot;import python_test;print(python_test.fun2(&#x27;$&#123;para&#125;&#x27;))&quot;</span></span><br></pre></td></tr></table></figure><p>执行命令：sh py_test_shell.sh hello</p><p>输出：有参数方法fun2且传入的参数为hello</p><h4 id="3-2-3-3-一次调用所有方法，放入一个集合中，再调用切割方法获取相应的值"><a href="#3-2-3-3-一次调用所有方法，放入一个集合中，再调用切割方法获取相应的值" class="headerlink" title="3.2.3 (3)一次调用所有方法，放入一个集合中，再调用切割方法获取相应的值"></a>3.2.3 (3)一次调用所有方法，放入一个集合中，再调用切割方法获取相应的值</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义变量</span></span><br><span class="line">para=$1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">将结果保存为一个变量ALL_RESULTS内</span></span><br><span class="line">ALL_RESULTS=$(python -c &quot;import python_test;print(python_test.fun1(),python_test.fun2(&#x27;$&#123;para&#125;&#x27;))&quot;)</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">分别打印第一个方法的返回与第二个方法的返回</span></span><br><span class="line">RESULTS_fun1=$(echo $ALL_RESULTS | cut -d&#x27; &#x27; -f1)</span><br><span class="line">RESULTS_fun2=$(echo $ALL_RESULTS | cut -d&#x27; &#x27; -f2)</span><br><span class="line">echo fun1方法的返回结果为：$RESULTS_fun1</span><br><span class="line">echo fun2方法的返回结果为：$RESULTS_fun2</span><br></pre></td></tr></table></figure><p><strong>输出：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fun1方法的返回结果为：无参数方法fun1</span><br><span class="line">fun2方法的返回结果为：有参数方法fun2且传入的参数为helloworld</span><br></pre></td></tr></table></figure><p>参考文章：<a href="https://www.cnblogs.com/mrwhite2020/p/16812198.html">参考文章</a></p>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读笔记---LLM + 图结构信息编码未知实体和关系进行TKGs补全任务</title>
      <link href="//2025-06-15-post12_%E5%A4%A7%E6%A8%A1%E5%9E%8B+%E5%9B%BE%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF%E8%9E%8D%E5%90%88/"/>
      <url>//2025-06-15-post12_%E5%A4%A7%E6%A8%A1%E5%9E%8B+%E5%9B%BE%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF%E8%9E%8D%E5%90%88/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="ce2f52627cf3bf5ed1dac37ac92673fe4912832669b0b67a250fcd7d2428b1db">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读笔记 </tag>
            
            <tag> TKGs </tag>
            
            <tag> 补全推理 </tag>
            
            <tag> LLM </tag>
            
            <tag> 图结构信息 </tag>
            
            <tag> private </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Transformers库的命名实体识别</title>
      <link href="//2025-06-12-post11/"/>
      <url>//2025-06-12-post11/</url>
      
        <content type="html"><![CDATA[<h2 id="step1-导入相关包"><a href="#step1-导入相关包" class="headerlink" title="step1 导入相关包"></a>step1 导入相关包</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> evaluate</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification</span><br></pre></td></tr></table></figure><h2 id="step2-加载数据集"><a href="#step2-加载数据集" class="headerlink" title="step2 加载数据集"></a>step2 加载数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> DatasetDict</span><br><span class="line">ner_datasets = DatasetDict.load_from_disk(<span class="string">&quot;ner_data&quot;</span>)</span><br><span class="line">ner_datasets</span><br></pre></td></tr></table></figure><p>输出：<br>DatasetDict({<br>    train: Dataset({<br>        features: [‘id’, ‘tokens’, ‘ner_tags’],<br>        num_rows: 20865<br>    })<br>    validation: Dataset({<br>        features: [‘id’, ‘tokens’, ‘ner_tags’],<br>        num_rows: 2319<br>    })<br>    test: Dataset({<br>        features: [‘id’, ‘tokens’, ‘ner_tags’],<br>        num_rows: 4637<br>    })<br>})</p><p><strong>查看tag标签类别</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label_list = ner_datasets[<span class="string">&quot;train&quot;</span>].features[<span class="string">&quot;ner_tags&quot;</span>].feature.names</span><br><span class="line">label_list <span class="comment"># 7类 0~6</span></span><br></pre></td></tr></table></figure><h2 id="step3-数据集预处理"><a href="#step3-数据集预处理" class="headerlink" title="step3 数据集预处理"></a>step3 数据集预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;hfl/chinese-macbert-base&quot;</span>) <span class="comment"># 加载分词器</span></span><br></pre></td></tr></table></figure><p><strong>使用分词器处理train[0]分词后的结果，将分词后的结果进行token化</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tokenizer(ner_datasets[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>][<span class="string">&quot;tokens&quot;</span>], is_split_into_words=<span class="literal">True</span>)   <span class="comment"># 对于已经做好tokenize的数据，要指定is_split_into_words参数为True</span></span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">   &#123;<span class="string">&#x27;input_ids&#x27;</span>: [<span class="number">101</span>, <span class="number">3862</span>, <span class="number">7157</span>, <span class="number">3683</span>, <span class="number">6612</span>, <span class="number">1765</span>, <span class="number">4157</span>, <span class="number">1762</span>, <span class="number">1336</span>, <span class="number">7305</span>, <span class="number">680</span>, <span class="number">7032</span>, <span class="number">7305</span>, <span class="number">722</span>, <span class="number">7313</span>, <span class="number">4638</span>, <span class="number">3862</span>, <span class="number">1818</span>, <span class="number">511</span>, <span class="number">102</span>], <span class="string">&#x27;token_type_ids&#x27;</span>: [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], <span class="string">&#x27;attention_mask&#x27;</span>: [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>有时候一个词，可能由于分词算法的原因会被分成多个子词，然后再转换成对应的token，如下：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">res = tokenizer(&quot;interesting word&quot;)</span><br><span class="line">print(res)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">&#123;&#x27;input_ids&#x27;: [101, 10673, 12865, 12921, 8181, 8681, 102], &#x27;token_type_ids&#x27;: [0, 0, 0, 0, 0, 0, 0], &#x27;attention_mask&#x27;: [1, 1, 1, 1, 1, 1, 1]&#125;</span><br><span class="line"># 除开101,102开始和结束token，我们会发现interesting这个词被分成了四个子词，然后再转换成token</span><br></pre></td></tr></table></figure><p><strong>那我们如何处理上述情况呢？由于标签tag是针对单个词的，现在我们ner任务，需要找到每个token所对应的tag，就需要用到word_ids()方法</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res.word_ids() <span class="comment"># 原始输入词语列表中的位置索引</span></span><br><span class="line"><span class="comment"># word_ids()方法返回token归属的词</span></span><br><span class="line">output: [<span class="literal">None</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="literal">None</span>]</span><br><span class="line"><span class="comment"># 也就是说上述的输出代表了每个token所对应的原始词，None则代表没有对应的，是额外添加的符号词元</span></span><br></pre></td></tr></table></figure><p><strong>那我们用这个返回结果究竟有什么用呢？</strong></p><p>答：通过定位token所对应的原始”整词”的索引，来定位从而获得每个token应该归属的标签tag。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 借助word_ids 实现标签映射</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_function</span>(<span class="params">examples</span>):</span><br><span class="line">    tokenized_exmaples = tokenizer(examples[<span class="string">&quot;tokens&quot;</span>], max_length=<span class="number">128</span>, truncation=<span class="literal">True</span>, is_split_into_words=<span class="literal">True</span>)</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(iterable=examples[<span class="string">&quot;ner_tags&quot;</span>]):</span><br><span class="line">        <span class="comment"># ! print(label) label即每个单独的词 对应 的tag标签</span></span><br><span class="line">        word_ids = tokenized_exmaples.word_ids(batch_index=i)</span><br><span class="line">        label_ids = []</span><br><span class="line">        <span class="keyword">for</span> word_id <span class="keyword">in</span> word_ids:</span><br><span class="line">            <span class="keyword">if</span> word_id <span class="keyword">is</span> <span class="literal">None</span>: <span class="comment"># ! 主要是为了将每个token对应的tag添加到label_ids，这样也就找到每个token对应的tag标签了</span></span><br><span class="line">                label_ids.append(-<span class="number">100</span>) <span class="comment"># ! 添加的特殊字符</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                label_ids.append(label[word_id])</span><br><span class="line">        labels.append(label_ids) </span><br><span class="line">    tokenized_exmaples[<span class="string">&quot;labels&quot;</span>] = labels </span><br><span class="line">    <span class="keyword">return</span> tokenized_exmaples</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(process_function(ner_datasets[<span class="string">&#x27;train&#x27;</span>][:<span class="number">2</span>]))</span><br><span class="line">output:</span><br><span class="line">&#123;<span class="string">&#x27;input_ids&#x27;</span>: [[<span class="number">101</span>, <span class="number">3862</span>, <span class="number">7157</span>, <span class="number">3683</span>, <span class="number">6612</span>, <span class="number">1765</span>, <span class="number">4157</span>, <span class="number">1762</span>, <span class="number">1336</span>, <span class="number">7305</span>, <span class="number">680</span>, <span class="number">7032</span>, <span class="number">7305</span>, <span class="number">722</span>, <span class="number">7313</span>, <span class="number">4638</span>, <span class="number">3862</span>, <span class="number">1818</span>, <span class="number">511</span>, <span class="number">102</span>], [<span class="number">101</span>, <span class="number">6821</span>, <span class="number">2429</span>, <span class="number">898</span>, <span class="number">2255</span>, <span class="number">988</span>, <span class="number">3717</span>, <span class="number">4638</span>, <span class="number">1300</span>, <span class="number">4289</span>, <span class="number">7667</span>, <span class="number">4507</span>, <span class="number">1744</span>, <span class="number">1079</span>, <span class="number">671</span>, <span class="number">3837</span>, <span class="number">4638</span>, <span class="number">6392</span>, <span class="number">6369</span>, <span class="number">2360</span>, <span class="number">712</span>, <span class="number">2898</span>, <span class="number">6392</span>, <span class="number">6369</span>, <span class="number">8024</span>, <span class="number">3146</span>, <span class="number">702</span>, <span class="number">2456</span>, <span class="number">5029</span>, <span class="number">5408</span>, <span class="number">5125</span>, <span class="number">5401</span>, <span class="number">5445</span>, <span class="number">2612</span>, <span class="number">2131</span>, <span class="number">511</span>, <span class="number">102</span>]], <span class="string">&#x27;token_type_ids&#x27;</span>: [[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], <span class="string">&#x27;attention_mask&#x27;</span>: [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]], <span class="string">&#x27;labels&#x27;</span>: [[-<span class="number">100</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, -<span class="number">100</span>], [-<span class="number">100</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, -<span class="number">100</span>]]&#125;</span><br></pre></td></tr></table></figure><p><strong>数据集预处理：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tokenized_datasets = ner_datasets.map(process_function, batched=True)</span><br><span class="line">tokenized_datasets</span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">DatasetDict(&#123;</span><br><span class="line">    train: Dataset(&#123;</span><br><span class="line">        features: [&#x27;id&#x27;, &#x27;tokens&#x27;, &#x27;ner_tags&#x27;, &#x27;input_ids&#x27;, &#x27;token_type_ids&#x27;, &#x27;attention_mask&#x27;, &#x27;labels&#x27;],</span><br><span class="line">        num_rows: 20865</span><br><span class="line">    &#125;)</span><br><span class="line">    validation: Dataset(&#123;</span><br><span class="line">        features: [&#x27;id&#x27;, &#x27;tokens&#x27;, &#x27;ner_tags&#x27;, &#x27;input_ids&#x27;, &#x27;token_type_ids&#x27;, &#x27;attention_mask&#x27;, &#x27;labels&#x27;],</span><br><span class="line">        num_rows: 2319</span><br><span class="line">    &#125;)</span><br><span class="line">    test: Dataset(&#123;</span><br><span class="line">        features: [&#x27;id&#x27;, &#x27;tokens&#x27;, &#x27;ner_tags&#x27;, &#x27;input_ids&#x27;, &#x27;token_type_ids&#x27;, &#x27;attention_mask&#x27;, &#x27;labels&#x27;],</span><br><span class="line">        num_rows: 4637</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h2 id="step4-创建模型"><a href="#step4-创建模型" class="headerlink" title="step4 创建模型"></a>step4 创建模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = AutoModelForTokenClassification.from_pretrained(<span class="string">&quot;hfl/chinese-macbert-base&quot;</span>, num_labels=<span class="built_in">len</span>(label_list))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.config.num_labels)</span><br><span class="line"><span class="comment"># output: 7</span></span><br></pre></td></tr></table></figure><h2 id="step5-创建评估函数"><a href="#step5-创建评估函数" class="headerlink" title="step5 创建评估函数"></a>step5 创建评估函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">seqeval = evaluate.load(<span class="string">&quot;seqeval_metric.py&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval_metric</span>(<span class="params">pred</span>):</span><br><span class="line">    predictions, labels = pred <span class="comment"># !预测结果和标签</span></span><br><span class="line">    predictions = np.argmax(predictions, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将id转换为原始的字符串类型的标签</span></span><br><span class="line">    true_predictions = [    </span><br><span class="line">        [label_list[p] <span class="keyword">for</span> p, l <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">        <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels) </span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    true_labels = [</span><br><span class="line">        [label_list[l] <span class="keyword">for</span> p, l <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">        <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels) </span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    result = seqeval.compute(predictions=true_predictions, references=true_labels, mode=<span class="string">&quot;strict&quot;</span>, scheme=<span class="string">&quot;IOB2&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;f1&quot;</span>: result[<span class="string">&quot;overall_f1&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br></pre></td></tr></table></figure><h2 id="step6-配置训练参数"><a href="#step6-配置训练参数" class="headerlink" title="step6 配置训练参数"></a>step6 <strong>配置训练参数</strong></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;models_for_ner&quot;</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">16</span>, <span class="comment"># 训练batch_size</span></span><br><span class="line">    per_device_eval_batch_size=<span class="number">32</span>, <span class="comment"># 验证batch_size</span></span><br><span class="line">    eval_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    save_strategy=<span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    metric_for_best_model=<span class="string">&quot;f1&quot;</span>, <span class="comment"># 衡量模型好坏依据的指标</span></span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>, </span><br><span class="line">    logging_steps=<span class="number">50</span>,</span><br><span class="line">    num_train_epochs=<span class="number">1</span> <span class="comment"># 训练的epoch数</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="Step7-创建训练器"><a href="#Step7-创建训练器" class="headerlink" title="Step7 创建训练器"></a>Step7 创建训练器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=args,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    compute_metrics=eval_metric,</span><br><span class="line">    data_collator=DataCollatorForTokenClassification(tokenizer=tokenizer)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="step8-模型训练"><a href="#step8-模型训练" class="headerlink" title="step8 模型训练"></a>step8 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br><span class="line">trainer.evaluate(eval_dataset=tokenized_datasets[<span class="string">&quot;test&quot;</span>])</span><br></pre></td></tr></table></figure><h2 id="Step9-模型预测"><a href="#Step9-模型预测" class="headerlink" title="Step9 模型预测"></a>Step9 模型预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用pipeline进行推理，要指定id2label</span></span><br><span class="line">model.config.id2label = &#123;idx: label <span class="keyword">for</span> idx, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(label_list)&#125;</span><br><span class="line"></span><br><span class="line">ner_pipe = pipeline(<span class="string">&quot;token-classification&quot;</span>, model=model, tokenizer=tokenizer, device=<span class="number">0</span>, aggregation_strategy=<span class="string">&quot;simple&quot;</span>) <span class="comment"># aggregation_startegy参数设置为None的话，则为单个token的预测结果，不会对结果进行聚合</span></span><br><span class="line"></span><br><span class="line">res = ner_pipe(<span class="string">&quot;小明在北京上班&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">  [&#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;PER&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9070835</span>,</span><br><span class="line">  <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;小 明&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;start&#x27;</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">&#x27;end&#x27;</span>: <span class="number">2</span>&#125;,</span><br><span class="line"> &#123;<span class="string">&#x27;entity_group&#x27;</span>: <span class="string">&#x27;LOC&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;score&#x27;</span>: <span class="number">0.9970835</span>,</span><br><span class="line">  <span class="string">&#x27;word&#x27;</span>: <span class="string">&#x27;北 京&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;start&#x27;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&#x27;end&#x27;</span>: <span class="number">5</span>&#125;]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
            <tag> 注意力机制 </tag>
            
            <tag> 大模型 </tag>
            
            <tag> transfomers </tag>
            
            <tag> Bert </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编码注意力机制的梳理(自用-分享)</title>
      <link href="//2025-06-09-post10_Attention/"/>
      <url>//2025-06-09-post10_Attention/</url>
      
        <content type="html"><![CDATA[<h3 id="编码注意力机制的梳理-自用-分享"><a href="#编码注意力机制的梳理-自用-分享" class="headerlink" title="编码注意力机制的梳理(自用-分享)"></a>编码注意力机制的梳理(自用-分享)</h3><p>  &emsp;&emsp;目前主流的大语言模型都是基于Transformer架构的，而Transformer架构的核心是Attention机制，所以了解Attention机制对于理解Transformer架构至关重要。</p><p>1.长序列建模中问题<br>过去在处理序列文本等数据时，大多采用RNN等模型，虽然部分应用场景下RNN模型的效果不错，但是面对长序列数据时，存在遗忘问题，从而导致对长序列模型建模时效果不是很好。因此，在2017年，Transformer模型应运而生，Transformer模型在长序列建模中，通过引入Attention机制，解决RNN模型中的遗忘问题，并大大提高模型的效果。</p><p>2.过去编码器-解码器模型存在问题<br>由于之前编码器-解码器模型，主要还是基于RNN模型，编码器生成整个文本的编码向量，再将这个编码向量输入给解码器，解码器基于编码向量生成输出预测，但是由于存在长距离遗忘信息丢失问题，编码向量会丢失长文本前段的信息，从而导致预测效果不好。然后注意力机制可以很好的解决这个问题，注意力机制可以捕获较长的依赖关系，获得更准确的编码向量表示。</p><h4 id="1-无训练权重的简单注意力机制"><a href="#1-无训练权重的简单注意力机制" class="headerlink" title="1.无训练权重的简单注意力机制"></a>1.无训练权重的简单注意力机制</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.无训练权重的简单注意力机制</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="comment"># 假设 [1,2,3] 是一个编码向量表示，[4,5,6]是一个编码向量表示</span></span><br><span class="line">w1 = <span class="number">0.5</span></span><br><span class="line">w2 = <span class="number">0.3</span>  <span class="comment"># w1 和 w2 可以理解为表示向量重要度的权重值，不同的值表示不同的注意力权重</span></span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>] * w1 + x[<span class="number">1</span>] * w2) <span class="comment"># 简单的加权求和，表示注意力机制</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用一个 （6,6）形状的矩阵，表示6个token，每个token嵌入向量大小为6的token嵌入表示</span></span><br><span class="line">x = torch.randn(<span class="number">6</span>,<span class="number">6</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># 通过点积(逐元素乘法)获得向量间的注意力权重</span></span><br><span class="line">attn_weights = torch.matmul(x,x.transpose(<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(attn_weights)</span><br><span class="line"><span class="comment"># 再对weights进行softmax归一化</span></span><br><span class="line">attn_weights = torch.softmax(attn_weights, dim=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(attn_weights)</span><br></pre></td></tr></table></figure><h4 id="2-实现带有可训练权重的自注意力机制"><a href="#2-实现带有可训练权重的自注意力机制" class="headerlink" title="2.实现带有可训练权重的自注意力机制"></a>2.实现带有可训练权重的自注意力机制</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttention</span>(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_in, d_out</span>):</span><br><span class="line">        <span class="built_in">super</span>(SelfAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.W_query = nn.Linear(d_in, d_out)</span><br><span class="line">        <span class="variable language_">self</span>.W_key = nn.Linear(d_in, d_out)</span><br><span class="line">        <span class="variable language_">self</span>.W_value = nn.Linear(d_in, d_out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        keys = <span class="variable language_">self</span>.W_key(x)</span><br><span class="line">        querys = <span class="variable language_">self</span>.W_query(x)    </span><br><span class="line">        values = <span class="variable language_">self</span>.W_value(x)</span><br><span class="line">        attn_scores = querys @ keys.transpose(-<span class="number">2</span>, -<span class="number">1</span>) <span class="comment"># 计算注意力分数</span></span><br><span class="line">        attn_weights = torch.softmax(</span><br><span class="line">            attn_scores / keys.shape[-<span class="number">1</span>] ** <span class="number">0.5</span>, dim = -<span class="number">1</span></span><br><span class="line">        ) <span class="comment"># 1.缩放点积防止梯度消失。 2.让输出分布和输入分布一致</span></span><br><span class="line">        attn_output = attn_weights @ values</span><br><span class="line">        <span class="keyword">return</span> attn_output</span><br></pre></td></tr></table></figure><h4 id="3-因果注意力机制"><a href="#3-因果注意力机制" class="headerlink" title="3.因果注意力机制"></a>3.因果注意力机制</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SelfAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_in, context_length, d_out</span>):</span><br><span class="line">        <span class="built_in">super</span>(SelfAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.W_query = nn.Linear(d_in, d_out)</span><br><span class="line">        <span class="variable language_">self</span>.W_key = nn.Linear(d_in, d_out)</span><br><span class="line">        <span class="variable language_">self</span>.W_value = nn.Linear(d_in, d_out)</span><br><span class="line">        <span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;mask&#x27;</span>, torch.triu(torch.ones(context_length, context_length),diagonal=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask = <span class="literal">None</span></span>):</span><br><span class="line">        query = <span class="variable language_">self</span>.W_query(x)</span><br><span class="line">        key = <span class="variable language_">self</span>.W_key(x)</span><br><span class="line">        value = <span class="variable language_">self</span>.W_value(x)</span><br><span class="line"></span><br><span class="line">        attention_scores = torch.matmul(query, key.transpose(-<span class="number">1</span>, -<span class="number">2</span>)) / math.sqrt(key.shaep[-<span class="number">1</span>]) </span><br><span class="line">        attention_scores = torch.masked_fill( <span class="comment"># 实现因果语言模型中的掩码，防止未来信息泄露</span></span><br><span class="line">            attention_scores, <span class="variable language_">self</span>.mask.<span class="built_in">bool</span>(), <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>)</span><br><span class="line">        )</span><br><span class="line">        attention_weights = F.softmax(attention_scores, dim=-<span class="number">1</span>) <span class="comment"># 进行softmax归一化</span></span><br><span class="line">        attention_weights = F.dropout(attention_weights, p=<span class="number">0.1</span>) <span class="comment"># dropout随机失活</span></span><br><span class="line">        output = torch.matmul(attention_weights, value)</span><br><span class="line">        <span class="keyword">return</span> output </span><br></pre></td></tr></table></figure><h4 id="4-多头注意力机制实现"><a href="#4-多头注意力机制实现" class="headerlink" title="4.多头注意力机制实现"></a>4.多头注意力机制实现</h4><h5 id="通过拼接多个单头注意力机制的模块实现"><a href="#通过拼接多个单头注意力机制的模块实现" class="headerlink" title="通过拼接多个单头注意力机制的模块实现"></a>通过拼接多个单头注意力机制的模块实现</h5><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.<span class="title class_">Module</span>):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"><span class="variable language_">self</span>, d_in, d_out, context_length, dropout, num_heads, qkv_bias=<span class="title class_">False</span></span>):</span><br><span class="line"><span class="variable language_">super</span>().__init__()</span><br><span class="line"><span class="variable language_">self</span>.heads = nn.<span class="title class_">ModuleList</span>(</span><br><span class="line">[<span class="title class_">CausualAttention</span>(d_in, d_out, context_length,dropout,qkv_bias) <span class="keyword">for</span> _ <span class="keyword">in</span> range(num_heads)]</span><br><span class="line">)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"><span class="variable language_">self</span>, x</span>):</span><br><span class="line"><span class="keyword">return</span> torch.cat([head(x) <span class="keyword">for</span> head <span class="keyword">in</span> <span class="variable language_">self</span>.heads], dim=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h5 id="多头注意力机制的模块实现"><a href="#多头注意力机制的模块实现" class="headerlink" title="多头注意力机制的模块实现"></a>多头注意力机制的模块实现</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_size, num_heads, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            embed_size (int): 输入嵌入的维度大小。</span></span><br><span class="line"><span class="string">            num_heads (int): 多头注意力中的头数。</span></span><br><span class="line"><span class="string">            dropout (float): Dropout 概率。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(MultiHeadAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="keyword">assert</span> embed_size % num_heads == <span class="number">0</span>, <span class="string">&quot;Embedding size must be divisible by num_heads&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.embed_size = embed_size</span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = embed_size // num_heads</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义线性层用于 Query, Key, Value 的投影</span></span><br><span class="line">        <span class="variable language_">self</span>.values = nn.Linear(<span class="variable language_">self</span>.head_dim, embed_size, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.keys = nn.Linear(<span class="variable language_">self</span>.head_dim, embed_size, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.queries = nn.Linear(<span class="variable language_">self</span>.head_dim, embed_size, bias=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 最后的线性映射层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc_out = nn.Linear(embed_size, embed_size)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Dropout 层</span></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, values, keys, query, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播函数。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            values (torch.Tensor): 值向量，形状为 [batch_size, value_len, embed_size]。</span></span><br><span class="line"><span class="string">            keys (torch.Tensor): 键向量，形状为 [batch_size, key_len, embed_size]。</span></span><br><span class="line"><span class="string">            query (torch.Tensor): 查询向量，形状为 [batch_size, query_len, embed_size]。</span></span><br><span class="line"><span class="string">            mask (torch.Tensor): 掩码张量，形状为 [batch_size, 1, 1, key_len]。</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            torch.Tensor: 输出张量，形状为 [batch_size, query_len, embed_size]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch_size = query.shape[<span class="number">0</span>] </span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将 Q, K, V 投影到嵌入空间</span></span><br><span class="line">        value_len, key_len, query_len = values.shape[<span class="number">1</span>], keys.shape[<span class="number">1</span>], query.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分割成多个头</span></span><br><span class="line">        values = values.reshape(batch_size, value_len, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">        keys = keys.reshape(batch_size, key_len, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">        queries = query.reshape(batch_size, query_len, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 转换为 [batch_size, num_heads, seq_len, head_dim]</span></span><br><span class="line">        values = values.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        keys = keys.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        queries = queries.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 缩放点积注意力</span></span><br><span class="line">        attn_scores = torch.matmul(queries, keys.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / torch.sqrt(</span><br><span class="line">            torch.tensor(<span class="variable language_">self</span>.head_dim, dtype=torch.float32)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            attn_scores = attn_scores.masked_fill(mask == <span class="number">1</span>, <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line"></span><br><span class="line">        attention = F.softmax(attn_scores, dim=-<span class="number">1</span>)</span><br><span class="line">        x = torch.matmul(<span class="variable language_">self</span>.dropout(attention), values)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 重新调整形状以合并多个头</span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous()</span><br><span class="line">        x = x.reshape(batch_size, query_len, <span class="variable language_">self</span>.embed_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最终的线性层</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc_out(x)</span><br></pre></td></tr></table></figure><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>大模型的核心就是 注意力分数矩阵 的计算，计算完注意力分数后，再计算出 最后的上下文向量，其中因果掩码添加是为了防止在大模型训练的时候泄露未来信息，这样避免了模型在学习过程中作弊，softmax处理使得注意力权重分布和之前仅在未掩码的位置上计算一样，dropout层的引入主要是为了避免大模型过拟合。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
            <tag> 注意力机制 </tag>
            
            <tag> 大模型 </tag>
            
            <tag> transfomer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读笔记---CyGNet阅读笔记-TKG推理任务</title>
      <link href="//2025-06-03-post9_CyGNet/"/>
      <url>//2025-06-03-post9_CyGNet/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="76f1fa0614f706858efbd18dec613830ca6463f4fb964bfe60d58b1f76467b57">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 论文阅读笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读笔记 </tag>
            
            <tag> TKGs </tag>
            
            <tag> 补全推理 </tag>
            
            <tag> private </tag>
            
            <tag> CyGNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一次实习及读研一年来心路历程总结</title>
      <link href="//2025-06-03-post8_%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
      <url>//2025-06-03-post8_%E5%AE%9E%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，您输入的密码错误，请检查后重新输入。" data-whm="抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="b436eec11ee0315874bf4a81c053fb12c3965cc55e4485fc0d398f499483ddfa">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">当前文章暂不对外可见，请输入密码后查看！</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> private </tag>
            
            <tag> 心路历程 </tag>
            
            <tag> 实习总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python包的安装和环境配置总结</title>
      <link href="//2025-05-28-post7_%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>//2025-05-28-post7_%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="1、查看自己CUDA版本号"><a href="#1、查看自己CUDA版本号" class="headerlink" title="1、查看自己CUDA版本号"></a>1、查看自己CUDA版本号</h2><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">nvidia-smi</span></span><br></pre></td></tr></table></figure><h2 id="2-安装torch-torchvision-torchaudio三大组件"><a href="#2-安装torch-torchvision-torchaudio三大组件" class="headerlink" title="2. 安装torch\torchvision\torchaudio三大组件"></a>2. 安装torch\torchvision\torchaudio三大组件</h2><p><a href="https://download.pytorch.org/whl">包下载管理站1</a> # 该链接貌似已失效<br><a href="https://mirrors.aliyun.com/pytorch-wheels/">包下载管理站2</a> # 阿里镜像站可用</p><p>首先选择torch，ctrl + F 搜索 [cu102-cp38-cp38-win] 这里cu102 是我们下载的 CUDA 10.2 版本，cp38-cp38 是说我们的 Python 版本是 3.8。如果要安装python3.9那将cp3.8改为cp3.9即可。</p><p><strong>需要注意的是 python版本号 CUDA版本号 以及 系统是我们需要的。</strong></p><h2 id="3-CONDA环境配置"><a href="#3-CONDA环境配置" class="headerlink" title="3.CONDA环境配置"></a>3.CONDA环境配置</h2><p>例如：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">conda</span> create -n xxx python=<span class="number">3</span>.<span class="number">9</span></span><br></pre></td></tr></table></figure><p>然后在终端执行命令:</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="built_in">activate</span> xxx</span><br></pre></td></tr></table></figure><h2 id="4、pip-WHL文件"><a href="#4、pip-WHL文件" class="headerlink" title="4、pip WHL文件"></a>4、pip WHL文件</h2><p>执行下面的命令安装轮子</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">pip</span> xxx.whl</span><br></pre></td></tr></table></figure><p>以上就是配置环境的简明教程</p><h2 id="torch-geometric安装"><a href="#torch-geometric安装" class="headerlink" title="torch_geometric安装"></a>torch_geometric安装</h2><p><strong>torch_geometric</strong>是PyG中必不可少的一个包，也是进行图神经网络学习的必备，然而安装这个包并运行一段简单的代码踩了不少坑，记录一下。</p><p>执行以下命令，先卸载相关包</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall torch-geometric torch-scatter torch-<span class="keyword">sparse</span> torch-cluster torch-<span class="built_in">spline</span>-<span class="built_in">conv</span></span><br></pre></td></tr></table></figure><p><a href="https://pytorch-geometric.com/whl/torch-1.4.0.html">torch_geometric包下载网站</a></p><p><strong>下载好 torch-scatter torch-sparse torch-cluster torch-spline-conv这四个包</strong></p><p>然后使用pip 命令安装好轮子</p><p>再执行：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip <span class="keyword">install</span> torch_geometric</span><br></pre></td></tr></table></figure><p>如果还是报错的话，可以尝试降低torch_geometric的版本号</p><p>亲测可用的版本组合:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">torch</span>-cluster  <span class="number">1</span>.<span class="number">6</span>.<span class="number">0</span></span><br><span class="line"><span class="attribute">torch</span>-geometric <span class="number">2</span>.<span class="number">0</span>.<span class="number">4</span></span><br><span class="line"><span class="attribute">torch</span>-scatter <span class="number">2</span>.<span class="number">0</span>.<span class="number">9</span></span><br><span class="line"><span class="attribute">torch</span>-sparse <span class="number">0</span>.<span class="number">6</span>.<span class="number">13</span></span><br><span class="line"><span class="attribute">torch</span>-spline-conv <span class="number">1</span>.<span class="number">2</span>.<span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pip </tag>
            
            <tag> 编程日记 </tag>
            
            <tag> 清华源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解决 pip 开了网络代理之后无法安装python包的问题</title>
      <link href="//2025-05-28-post6_pip_network/"/>
      <url>//2025-05-28-post6_pip_network/</url>
      
        <content type="html"><![CDATA[<p>问题描述：<br>开了网络代理后，无法在终端直接使用pip和conda命令，会报错：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ pip install netsm</span><br><span class="line">Looking <span class="keyword">in</span> indexes: https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">WARNING: Retrying (Retry(total=<span class="number">4</span>, connect=<span class="literal">None</span>, read=<span class="literal">None</span>, redirect=<span class="literal">None</span>, status=<span class="literal">None</span>)) after connection broken by <span class="string">&#x27;SSLError(SSLEOFError(8, &#x27;</span>EOF occurred <span class="keyword">in</span> violation of protocol (_ssl.c:<span class="number">1123</span>)<span class="string">&#x27;))&#x27;</span>: /simple/netsm/</span><br><span class="line">WARNING: Retrying (Retry(total=<span class="number">3</span>, connect=<span class="literal">None</span>, read=<span class="literal">None</span>, redirect=<span class="literal">None</span>, status=<span class="literal">None</span>)) after connection broken by <span class="string">&#x27;SSLError(SSLEOFError(8, &#x27;</span>EOF occurred <span class="keyword">in</span> violation of protocol (_ssl.c:<span class="number">1123</span>)<span class="string">&#x27;))&#x27;</span>: /simple/netsm/</span><br><span class="line">WARNING: Retrying (Retry(total=<span class="number">2</span>, connect=<span class="literal">None</span>, read=<span class="literal">None</span>, redirect=<span class="literal">None</span>, status=<span class="literal">None</span>)) after connection broken by <span class="string">&#x27;SSLError(SSLEOFError(8, &#x27;</span>EOF occurred <span class="keyword">in</span> violation of protocol (_ssl.c:<span class="number">1123</span>)<span class="string">&#x27;))&#x27;</span>: /simple/netsm/</span><br><span class="line">WARNING: Retrying (Retry(total=<span class="number">1</span>, connect=<span class="literal">None</span>, read=<span class="literal">None</span>, redirect=<span class="literal">None</span>, status=<span class="literal">None</span>)) after connection broken by <span class="string">&#x27;SSLError(SSLEOFError(8, &#x27;</span>EOF occurred <span class="keyword">in</span> violation of protocol (_ssl.c:<span class="number">1123</span>)<span class="string">&#x27;))&#x27;</span>: /simple/netsm/</span><br><span class="line">WARNING: Retrying (Retry(total=<span class="number">0</span>, connect=<span class="literal">None</span>, read=<span class="literal">None</span>, redirect=<span class="literal">None</span>, status=<span class="literal">None</span>)) after connection broken by <span class="string">&#x27;SSLError(SSLEOFError(8, &#x27;</span>EOF occurred <span class="keyword">in</span> violation of protocol (_ssl.c:<span class="number">1123</span>)<span class="string">&#x27;))&#x27;</span>: /simple/netsm/</span><br><span class="line">Could <span class="keyword">not</span> fetch URL https://pypi.tuna.tsinghua.edu.cn/simple/netsm/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host=<span class="string">&#x27;pypi.tuna.tsinghua.edu.cn&#x27;</span>, port=<span class="number">443</span>): Max retries exceeded <span class="keyword">with</span> url: /simple/netsm/ (Caused by SSLError(SSLEOFError(<span class="number">8</span>, <span class="string">&#x27;EOF occurred in violation of protocol (_ssl.c:1123)&#x27;</span>))) - skipping</span><br><span class="line">ERROR: Could <span class="keyword">not</span> find a version that satisfies the requirement netsm (<span class="keyword">from</span> versions: none)</span><br><span class="line">ERROR: No matching distribution found <span class="keyword">for</span> netsm</span><br></pre></td></tr></table></figure><p>问题分析：<br>在一开始入坑深度学习的时候，相信大家都会配置国内镜像源，这样下载包的速度会快上许多。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip config <span class="keyword">set</span> <span class="keyword">global</span>.<span class="built_in">index</span>-url https://pypi.tuna.tsinghua.edu.<span class="keyword">cn</span>/simple</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>出现上面的问题，一开始猜测是网络方面的问题，比如拦截之类的。尝试关掉代理软件之后就可以正常使用了，但是这样的方式比较麻烦，每次都得关闭打开。<br>进一步想，可能是因为配置了国内镜像源网站的原因，流量通过代理去了国外，再回来访问镜像源网站的时候，会被拒绝访问，因此就出现了上面的问题。</p><p>搜了一下解决方式：<br>在代理上进行配置网站，使得访问该网站的时候绕开代理，这样就可以解决问题了。</p><p><img src="/2025-05-28-post6_pip_network/1.png"></p><p>但是后面发现，重启代理软件之后又失效了，于是我打开之前配置的代理绕开网站配置，发现又被重置成原本的设置了，原来是代理小猫咪的原因，使用小猫咪的是因为小猫咪在帮你开系统代理时候给你覆盖回来了，所以系统会恢复，可以在对应软件里面这样设置：<br>1、进入 Settings （设置）页面</p><p>2、点击 System proxy Bypass （系统代理）右边 Edit 小字打开编辑界面</p><p><img src="/2025-05-28-post6_pip_network/2.png"></p><p>3、若要增加绕过example.com域名，只需在修改编辑界面内容为：（我们这个问题应该就是仿照着添加“pypi.tuna.tsinghua.edu.cn”）</p><p><img src="/2025-05-28-post6_pip_network/3.png"></p>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pip </tag>
            
            <tag> 编程日记 </tag>
            
            <tag> 清华源 </tag>
            
            <tag> debug </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vscode上一种优雅的debug方式</title>
      <link href="//2025-05-28-post5_debug_vscode/"/>
      <url>//2025-05-28-post5_debug_vscode/</url>
      
        <content type="html"><![CDATA[<h1 id="vscode-如何debug-python-torchrun-deepspeed-自用，防忘记"><a href="#vscode-如何debug-python-torchrun-deepspeed-自用，防忘记" class="headerlink" title="vscode 如何debug python torchrun deepspeed[自用，防忘记]"></a>vscode 如何debug python torchrun deepspeed[自用，防忘记]</h1><h2 id="⚠️-写在前面-一定要看"><a href="#⚠️-写在前面-一定要看" class="headerlink" title="⚠️ 写在前面(一定要看)"></a>⚠️ 写在前面(一定要看)</h2><ol><li>debug程序的方式有很多种。每一种方式都各有缺点：有的方式虽然优雅，但是局限性很大；有的方式麻烦，但是局限性小。<ul><li>常规方式：<ul><li>优点：然后可以观察所有线程。一劳永逸。</li><li>缺点：就是写参数很麻烦，但是你可以让chatgpt等大模型帮你写。</li></ul></li><li>最最最优雅的方式：<ul><li>优点：就是需要在代码里面，加入几行代码。方便快捷。</li><li>缺点：有时候断点不生效，只能在一个线程里面启动。</li></ul></li></ul></li><li>建议先使用【常规形式】、如果【常规形式】不够用，再使用【最最最优雅的方式】</li></ol><h3 id="B站手把手视频"><a href="#B站手把手视频" class="headerlink" title="B站手把手视频"></a>B站手把手视频</h3><ol><li>常规方式：<a href="https://www.bilibili.com/video/BV1Hh4y1i7Li">https://www.bilibili.com/video/BV1Hh4y1i7Li</a><ul><li>对于torchrun这种形式：<a href="https://www.bilibili.com/video/BV1b84y1R75V">https://www.bilibili.com/video/BV1b84y1R75V</a></li><li>对于deepspeed这种形式: <a href="https://www.bilibili.com/video/BV1xC4y1P7LH">https://www.bilibili.com/video/BV1xC4y1P7LH</a></li></ul></li><li>最最最优雅的方式：<a href="https://www.bilibili.com/video/BV1wt421V718">https://www.bilibili.com/video/BV1wt421V718</a></li></ol><h2 id="最优雅的方式"><a href="#最优雅的方式" class="headerlink" title="最优雅的方式"></a>最优雅的方式</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ol><li>安装包 <code>pip install debugpy -U</code></li><li>安装vscode关于python的相关插件</li></ol><h3 id="写配置"><a href="#写配置" class="headerlink" title="写配置"></a>写配置</h3><p>一般情况下，大家都是使用deepspeed、torchrun运行代码。参数都特别多，然后都是使用<code>sh xxxx.sh</code>启动脚本。</p><h4 id="在python代码里面（最前面加上这句话）"><a href="#在python代码里面（最前面加上这句话）" class="headerlink" title="在python代码里面（最前面加上这句话）"></a>在python代码里面（最前面加上这句话）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> debugpy</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 5678 is the default attach port in the VS Code debug configurations. Unless a host and port are specified, host defaults to 127.0.0.1</span></span><br><span class="line">    debugpy.listen((<span class="string">&quot;localhost&quot;</span>, <span class="number">9501</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Waiting for debugger attach&quot;</span>)</span><br><span class="line">    debugpy.wait_for_client()</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="在vscode的launch-json的configuration里面，加上这个配置"><a href="#在vscode的launch-json的configuration里面，加上这个配置" class="headerlink" title="在vscode的launch.json的configuration里面，加上这个配置"></a>在vscode的launch.json的configuration里面，加上这个配置</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sh_file_debug&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;debugpy&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;attach&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;connect&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;host&quot;</span><span class="punctuation">:</span> <span class="string">&quot;localhost&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;port&quot;</span><span class="punctuation">:</span> <span class="number">9501</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>🚨 上面的端口号都写一样。别搞错了。</p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><ol><li>就正常启动，直接<code>sh xxx.sh</code></li><li>在你需要debug的python文件，打上debug断点。</li><li>你看打印出来的东西，是不是出现<code>Waiting for debugger attach</code>.一般来说，都很快，就出现了。</li><li>再在vscode的debug页面，选择<code>sh_file_debug</code>进行debug。</li><li>就基本上完成了。确实是很方便。</li><li><strong>debug结束之后，别忘记把代码里面的 添加的代码，注销掉</strong></li></ol><h2 id="参考仓库"><a href="#参考仓库" class="headerlink" title="参考仓库"></a>参考仓库</h2><p><a href="https://github.com/yuanzhoulvpi2017/vscode_debug_transformers">参考仓库</a></p>]]></content>
      
      
      <categories>
          
          <category> 编程日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vscode </tag>
            
            <tag> 编程日记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bert用于命名实体识别任务（NER）</title>
      <link href="//2025-05-23-post4_Bert_ner/"/>
      <url>//2025-05-23-post4_Bert_ner/</url>
      
        <content type="html"><![CDATA[<h3 id="前记："><a href="#前记：" class="headerlink" title="前记："></a>前记：</h3><p>BERT(Bidirectional Encoder Representation from Transformers)是2018年10月Google AI研究院提出的一种预训练-微调大模型，和GPT属于是同一时期的产物。BERT在多项自然语言处理任务上都实现了SOTA，抛弃了传统模型，在一种任务上需要修改模型架构的方式，而是同一个模型架构在不需要修改的情况下，应用于多个任务上。因此，一经问世就引起了学术界极大地关注，甚至超过了GPT。</p><p>BERT的网络架构使用的是基于Transformer中的Encoder部分，由于其使用Attention的关系，从而避免了传统网络结构，诸如RNN，LSTM，GRU等的遗忘问题，可以捕获一个长序列不同token的相关性问题。</p><p>Bert架构图如下：<br><img src="/2025-05-23-post4_Bert_ner/Bert1.jpg" alt="Bert架构图"></p><h3 id="网络结构介绍："><a href="#网络结构介绍：" class="headerlink" title="网络结构介绍："></a>网络结构介绍：</h3><p>这里重点介绍一下Bert的嵌入编码部分，后面部分就是Encoder模块的堆叠了，并没有什么新奇的。<br>Bert的嵌入编码有三部分，分别是token Embedding，position Embedding, segment Embedding，之所以这里需要segment Embedding，是因为在Bert的预训练任务中有两个训练任务一个是掩码填充预测，一个NSP(Next Sentence Prediction)预测。</p><h3 id="NER任务："><a href="#NER任务：" class="headerlink" title="NER任务："></a>NER任务：</h3><p>命名实体识别——Named Entity Recognition——简称NER，是指从文本中识别出具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。 简单举例： 识别出的实体结果： 结果显示就把举例文本中的具有特定意义的实体，机构名和人名以及它们的具体位置都识别出来了。 以上就是一个NER任务的实际样例，在做具体的项目的时候，往往涉及到的实体类型更多，有可能成百上千，然后数据量更多。</p><h3 id="使用Bert用于NER任务"><a href="#使用Bert用于NER任务" class="headerlink" title="使用Bert用于NER任务"></a>使用Bert用于NER任务</h3><p>所使用到的数据集链接：<a href="https://drive.google.com/drive/folders/1XtAv4ePsRi20P_-qjnJyu45H9an_2VTJ?usp=drive_link">数据集</a></p><p>首先是数据集的处理：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NerDataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,filename,tokenizer</span>):</span><br><span class="line">        <span class="variable language_">self</span>.tokenizer=tokenizer</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&#x27;r&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="variable language_">self</span>.tokens_arr,<span class="variable language_">self</span>.labels_arr=<span class="variable language_">self</span>._preprocess(json.load(f)) <span class="comment"># 读取json文件内容并进行预处理</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_preprocess</span>(<span class="params">self,data</span>):</span><br><span class="line">        tokens_arr,labels_arr=[],[] <span class="comment"># 对标注数据的token 和 token_label_list进行处理</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">            text=item[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;text&#x27;</span>] <span class="comment"># 原始文本</span></span><br><span class="line">            annotations=item[<span class="string">&#x27;annotations&#x27;</span>] <span class="comment"># 标签数据</span></span><br><span class="line"></span><br><span class="line">            ch_tokens_list=[]</span><br><span class="line">            ch_labels_list=[]</span><br><span class="line">            <span class="keyword">for</span> ch <span class="keyword">in</span> text: <span class="comment"># tokenizer by char</span></span><br><span class="line">                ch_tokens=<span class="variable language_">self</span>.tokenizer([ch],add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">len</span>(ch_tokens.input_ids[<span class="number">0</span>])&lt;=<span class="number">1</span></span><br><span class="line">                <span class="comment"># print(ch_tokens.input_ids[0])</span></span><br><span class="line">                ch_tokens_list.append(ch_tokens.input_ids[<span class="number">0</span>])</span><br><span class="line">                ch_labels_list.append([<span class="string">&#x27;O&#x27;</span>]*<span class="built_in">len</span>(ch_tokens.input_ids[<span class="number">0</span>])) <span class="comment"># 全部复制为&#x27;o&#x27;</span></span><br><span class="line">            <span class="keyword">for</span> anno <span class="keyword">in</span> annotations[<span class="number">0</span>][<span class="string">&#x27;result&#x27;</span>]:</span><br><span class="line">                anno=anno[<span class="string">&#x27;value&#x27;</span>]</span><br><span class="line">                start,end,text,label=anno[<span class="string">&#x27;start&#x27;</span>],anno[<span class="string">&#x27;end&#x27;</span>],anno[<span class="string">&#x27;text&#x27;</span>],anno[<span class="string">&#x27;labels&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">                first=<span class="literal">True</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start,end): <span class="comment"># 对数据进行标注</span></span><br><span class="line">                    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ch_labels_list[i])):</span><br><span class="line">                        <span class="keyword">if</span> first:</span><br><span class="line">                            ch_labels_list[i][j]=label+<span class="string">&#x27;-B&#x27;</span> <span class="comment"># 开始片段</span></span><br><span class="line">                            first=<span class="literal">False</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            ch_labels_list[i][j]=label+<span class="string">&#x27;-I&#x27;</span> <span class="comment"># 中间片段</span></span><br><span class="line">            item_tokens=[]</span><br><span class="line">            item_labels=[]</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ch_tokens_list)):</span><br><span class="line">                item_tokens.extend(ch_tokens_list[i]) <span class="comment"># 一个token样本</span></span><br><span class="line">                item_labels.extend(ch_labels_list[i]) <span class="comment"># 对应的一个标签样本</span></span><br><span class="line">            tokens_arr.append(item_tokens)</span><br><span class="line">            labels_arr.append(item_labels)</span><br><span class="line">        <span class="keyword">return</span> tokens_arr,labels_arr <span class="comment"># 返回所有的token和token标签</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,idx</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.tokens_arr[idx],<span class="variable language_">self</span>.labels_arr[idx]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.tokens_arr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># with open(&#x27;/content/drive/MyDrive/Colab Notebooks/ner-bert-crf/data/train_label.json&#x27;,&#x27;r&#x27;,encoding=&#x27;utf-8&#x27;) as f:</span></span><br><span class="line">      <span class="comment"># print(type(json.load(f)[0]))</span></span><br><span class="line">      <span class="comment"># print(json.load(f)[0])</span></span><br><span class="line">    <span class="keyword">from</span> modelscope <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">    tokenizer=AutoTokenizer.from_pretrained(<span class="string">&#x27;google-bert/bert-base-chinese&#x27;</span>) <span class="comment"># 加载分词器</span></span><br><span class="line">    ds=NerDataset(<span class="string">&#x27;/content/drive/MyDrive/Colab Notebooks/ner-bert-crf/data/train_label.json&#x27;</span>,tokenizer)  <span class="comment"># 加载标注数据</span></span><br><span class="line">    tokens,labels=ds[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(tokens,<span class="built_in">len</span>(tokens)) </span><br><span class="line">    <span class="built_in">print</span>(tokenizer.decode(tokens))</span><br><span class="line">    <span class="built_in">print</span>(labels,<span class="built_in">len</span>(labels)) <span class="comment"># 标注结果</span></span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1745</span>, <span class="number">711</span>, <span class="number">1266</span>, <span class="number">776</span>, <span class="number">1920</span>, <span class="number">2110</span>, <span class="number">1744</span>, <span class="number">2157</span>, <span class="number">1355</span>, <span class="number">2245</span>, <span class="number">4777</span>, <span class="number">4955</span>, <span class="number">7368</span>, <span class="number">3136</span>, <span class="number">2956</span>, <span class="number">510</span>, <span class="number">704</span>, <span class="number">1744</span>, <span class="number">5307</span>, <span class="number">3845</span>, <span class="number">4777</span>, <span class="number">4955</span>, <span class="number">704</span>, <span class="number">2552</span>, <span class="number">712</span>, <span class="number">818</span>, <span class="number">2001</span>, <span class="number">3817</span>, <span class="number">1745</span>, <span class="number">120</span>, <span class="number">1358</span>, <span class="number">6393</span>, <span class="number">5442</span>, <span class="number">897</span>, <span class="number">1745</span>] <span class="number">35</span></span><br><span class="line">图 为 北 京 大 学 国 家 发 展 研 究 院 教 授 、 中 国 经 济 研 究 中 心 主 任 姚 洋 图 / 受 访 者 供 图</span><br><span class="line">[<span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;COUNTRY-B&#x27;</span>, <span class="string">&#x27;COUNTRY-I&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;PERSON-B&#x27;</span>, <span class="string">&#x27;PERSON-I&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>, <span class="string">&#x27;O&#x27;</span>] <span class="number">35</span></span><br></pre></td></tr></table></figure><p>模型构建：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchcrf <span class="keyword">import</span> CRF</span><br><span class="line"><span class="keyword">from</span> modelscope <span class="keyword">import</span> BertModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NerBertCrfModel</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_tags</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.bert=BertModel.from_pretrained(<span class="string">&#x27;google-bert/bert-base-chinese&#x27;</span>) <span class="comment"># 加载Bert中文模型</span></span><br><span class="line">        <span class="variable language_">self</span>.hidden=torch.nn.Linear(in_features=<span class="number">768</span>,out_features=num_tags) <span class="comment"># 输出设置tag类别数</span></span><br><span class="line">        <span class="variable language_">self</span>.crf=CRF(num_tags=num_tags,batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.bert.parameters(): <span class="comment"># 冻结bert原始预训练的参数</span></span><br><span class="line">            p.requires_grad=<span class="literal">False</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,input_ids,attention_mask,token_type_ids,labels</span>):</span><br><span class="line">        emissions=<span class="variable language_">self</span>.bert(input_ids,attention_mask,token_type_ids)</span><br><span class="line">        <span class="comment"># print(emissions.last_hidden_state.shape) # (2,20,768)</span></span><br><span class="line">        emissions=<span class="variable language_">self</span>.hidden(emissions.last_hidden_state) <span class="comment"># (2,20,5)</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="variable language_">self</span>.crf(emissions=emissions,tags=labels,mask=attention_mask) <span class="comment"># loss 对数似然值取相反数，作为损失函数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,input_ids,attention_mask,token_type_ids</span>):</span><br><span class="line">        emissions=<span class="variable language_">self</span>.bert(input_ids,attention_mask,token_type_ids)</span><br><span class="line">        emissions=<span class="variable language_">self</span>.hidden(emissions.last_hidden_state)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.crf.decode(emissions=emissions,mask=attention_mask)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    model=NerBertCrfModel(num_tags=<span class="number">5</span>)</span><br><span class="line">    input_ids=torch.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">2</span>,<span class="number">20</span>))</span><br><span class="line">    attention_mask=torch.ones_like(input_ids).<span class="built_in">bool</span>()</span><br><span class="line">    token_type_ids=torch.zeros_like(input_ids)</span><br><span class="line">    labels=torch.randint(<span class="number">0</span>,<span class="number">5</span>,size=(<span class="number">2</span>,<span class="number">20</span>))</span><br><span class="line">    loss=model(input_ids,attention_mask,token_type_ids,labels)</span><br><span class="line">    predict=model.predict(input_ids,attention_mask,token_type_ids)</span><br><span class="line">    <span class="built_in">print</span>(predict)</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># torch.Size([2, 20, 768])</span></span><br><span class="line">[[<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]]</span><br></pre></td></tr></table></figure><p>训练代码部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from dataset import NerDataset</span></span><br><span class="line"><span class="comment"># from model import NerBertCrfModel</span></span><br><span class="line"><span class="keyword">from</span> modelscope <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line">device=<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line"></span><br><span class="line">labels=&#123;<span class="string">&#x27;COUNTRY-B&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;COUNTRY-I&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;PERSON-B&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;PERSON-I&#x27;</span>:<span class="number">3</span>,<span class="string">&#x27;O&#x27;</span>:<span class="number">4</span>&#125; <span class="comment"># 标签ID映射</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch,tokenizer</span>): <span class="comment"># 对数据进行批量处理，填充成相同长度</span></span><br><span class="line">    bos_id=tokenizer.convert_tokens_to_ids([<span class="string">&#x27;[CLS]&#x27;</span>]) <span class="comment"># 开始符号ID</span></span><br><span class="line">    eos_id=tokenizer.convert_tokens_to_ids([<span class="string">&#x27;[SEP]&#x27;</span>]) <span class="comment"># 结束符号ID</span></span><br><span class="line">    pad_id=tokenizer.convert_tokens_to_ids([<span class="string">&#x27;[PAD]&#x27;</span>]) <span class="comment"># 填充符号ID</span></span><br><span class="line">    batch_x,batch_y,batch_attn_mask,batch_token_type_ids=[],[],[],[]</span><br><span class="line">    max_seq_len=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> batch: <span class="comment"># 训练数据token处理</span></span><br><span class="line">        x=bos_id+sample[<span class="number">0</span>]+eos_id</span><br><span class="line">        batch_x.append(x)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(x)&gt;max_seq_len:</span><br><span class="line">            max_seq_len=<span class="built_in">len</span>(x)</span><br><span class="line">        y=[labels[<span class="string">&#x27;O&#x27;</span>]]+[labels[label] <span class="keyword">for</span> label <span class="keyword">in</span> sample[<span class="number">1</span>]]+[labels[<span class="string">&#x27;O&#x27;</span>]]</span><br><span class="line">        batch_y.append(y)</span><br><span class="line">    <span class="comment"># padding</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;max:&#x27;</span>,max_seq_len)</span><br><span class="line">    <span class="keyword">for</span> i,x <span class="keyword">in</span> <span class="built_in">enumerate</span>(batch_x): <span class="comment"># batch_attn_mask是填充掩码，标注出PAD填充掩码</span></span><br><span class="line">        batch_attn_mask.append([<span class="number">1</span>]*<span class="built_in">len</span>(x)+[<span class="number">0</span>]*(max_seq_len-<span class="built_in">len</span>(x)))</span><br><span class="line">        batch_y[i].extend([labels[<span class="string">&#x27;O&#x27;</span>]]*(max_seq_len-<span class="built_in">len</span>(x)))</span><br><span class="line">        x.extend(pad_id*(max_seq_len-<span class="built_in">len</span>(x))) <span class="comment"># 填充 x</span></span><br><span class="line">        batch_token_type_ids.append([<span class="number">0</span>]*<span class="built_in">len</span>(x)) <span class="comment"># sentence A 分段掩码</span></span><br><span class="line">    <span class="keyword">return</span> torch.tensor(batch_x,dtype=torch.long),torch.tensor(batch_attn_mask,dtype=torch.<span class="built_in">bool</span>),torch.tensor(batch_token_type_ids,dtype=torch.long),torch.tensor(batch_y,dtype=torch.long)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tokenizer=AutoTokenizer.from_pretrained(<span class="string">&#x27;google-bert/bert-base-chinese&#x27;</span>) <span class="comment"># 加载分词器</span></span><br><span class="line">    model=NerBertCrfModel(num_tags=<span class="built_in">len</span>(labels)).to(device) <span class="comment"># 加载模型</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        model.load_state_dict(torch.load(<span class="string">&#x27;model.pt&#x27;</span>)) <span class="comment"># 加载模型权重</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    optimizer=torch.optim.Adam([p <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad],lr=<span class="number">6e-5</span>)</span><br><span class="line"></span><br><span class="line">    dataset=NerDataset(<span class="string">&#x27;/content/drive/MyDrive/Colab Notebooks/ner-bert-crf/data/train_label.json&#x27;</span>,tokenizer)</span><br><span class="line">    dataloader=torch.utils.data.DataLoader(dataset,batch_size=<span class="number">16</span>,shuffle=<span class="literal">True</span>,persistent_workers=<span class="literal">True</span>,num_workers=<span class="number">2</span>,collate_fn=functools.partial(collate_fn,tokenizer=tokenizer))</span><br><span class="line"></span><br><span class="line">    steps=<span class="number">0</span></span><br><span class="line">    epoch=<span class="number">0</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        pbar=tqdm.tqdm(dataloader,total=<span class="built_in">len</span>(dataloader),ncols=<span class="number">100</span>)</span><br><span class="line">        <span class="keyword">for</span> batch_x,batch_attn_mask,batch_token_type_ids,batch_y <span class="keyword">in</span> pbar:</span><br><span class="line">            batch_x,batch_attn_mask,batch_token_type_ids,batch_y=batch_x.to(device),batch_attn_mask.to(device),batch_token_type_ids.to(device),batch_y.to(device)</span><br><span class="line">            loss=model(batch_x,batch_attn_mask,batch_token_type_ids,batch_y)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            steps+=<span class="number">1</span></span><br><span class="line">            pbar.set_description(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>&#x27;</span>)</span><br><span class="line">            pbar.set_postfix(loss=loss.item(),steps=steps)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># checkpoint</span></span><br><span class="line">            <span class="keyword">if</span> steps%<span class="number">300</span>==<span class="number">0</span>:</span><br><span class="line">                torch.save(model.state_dict(),<span class="string">&#x27;.model.pt&#x27;</span>)</span><br><span class="line">                os.replace(<span class="string">&#x27;.model.pt&#x27;</span>,<span class="string">&#x27;model.pt&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> epoch == <span class="number">100</span>:</span><br><span class="line">              torch.save(model.state_dict(),<span class="string">&#x27;.model.pt&#x27;</span>)</span><br><span class="line">              os.replace(<span class="string">&#x27;.model.pt&#x27;</span>,<span class="string">&#x27;model.pt&#x27;</span>)</span><br><span class="line">              <span class="built_in">print</span>(<span class="string">&#x27;finish...&#x27;</span>)</span><br><span class="line">              <span class="keyword">break</span></span><br><span class="line">        epoch+=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>evolution：这部分主要是对预测的后处理结果，处理后返回后处理的识别分类元组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchcrf <span class="keyword">import</span> CRF</span><br><span class="line"><span class="comment"># from model import NerBertCrfModel</span></span><br><span class="line"><span class="keyword">from</span> modelscope <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line">device=<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">labels=&#123;<span class="string">&#x27;COUNTRY-B&#x27;</span>:<span class="number">0</span>,<span class="string">&#x27;COUNTRY-I&#x27;</span>:<span class="number">1</span>,<span class="string">&#x27;PERSON-B&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;PERSON-I&#x27;</span>:<span class="number">3</span>,<span class="string">&#x27;O&#x27;</span>:<span class="number">4</span>&#125;</span><br><span class="line">labels_rev=<span class="built_in">dict</span>((v,k) <span class="keyword">for</span> k,v <span class="keyword">in</span> labels.items())</span><br><span class="line"></span><br><span class="line">tokenizer=AutoTokenizer.from_pretrained(<span class="string">&#x27;google-bert/bert-base-chinese&#x27;</span>)</span><br><span class="line">model=NerBertCrfModel(num_tags=<span class="built_in">len</span>(labels)).to(device)</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;/content/drive/MyDrive/Colab Notebooks/model.pt&#x27;</span>))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ner</span>(<span class="params">s</span>):</span><br><span class="line">    tokens=[]</span><br><span class="line">    <span class="keyword">for</span> ch <span class="keyword">in</span> s:</span><br><span class="line">        ret=tokenizer([ch],add_special_tokens=<span class="literal">False</span>)</span><br><span class="line">        tokens=tokens+ret.input_ids[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    bos_id=tokenizer.convert_tokens_to_ids([<span class="string">&#x27;[CLS]&#x27;</span>])</span><br><span class="line">    eos_id=tokenizer.convert_tokens_to_ids([<span class="string">&#x27;[SEP]&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    input_ids=torch.tensor(bos_id+tokens+eos_id,dtype=torch.long).to(device)</span><br><span class="line">    attn_mask=torch.tensor([<span class="number">1</span>]*<span class="built_in">len</span>(input_ids),dtype=torch.<span class="built_in">bool</span>).to(device)</span><br><span class="line">    type_ids=torch.tensor([<span class="number">0</span>]*<span class="built_in">len</span>(input_ids),dtype=torch.long).to(device)</span><br><span class="line"></span><br><span class="line">    pred=model.predict(input_ids.unsqueeze(<span class="number">0</span>),attn_mask.unsqueeze(<span class="number">0</span>),type_ids.unsqueeze(<span class="number">0</span>))</span><br><span class="line">    <span class="comment"># ignore [CLS] and [SEP]</span></span><br><span class="line">    input_ids=input_ids[<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">    pred=pred[<span class="number">0</span>][<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">    start=<span class="literal">None</span></span><br><span class="line">    entity=<span class="string">&#x27;&#x27;</span></span><br><span class="line">    ner_result=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pred)):</span><br><span class="line">        pred_label=labels_rev[pred[i]]</span><br><span class="line">        pred_label_splits=pred_label.split(<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">        pred_label_first=pred_label_splits[<span class="number">0</span>]</span><br><span class="line">        pred_label_second=<span class="string">&#x27;&#x27;</span> <span class="keyword">if</span> <span class="built_in">len</span>(pred_label_splits)&lt;=<span class="number">1</span> <span class="keyword">else</span> pred_label_splits[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> start <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> pred_label_second==<span class="string">&#x27;B&#x27;</span>: <span class="comment"># entiry start</span></span><br><span class="line">            start=i</span><br><span class="line">            entity=pred_label_first</span><br><span class="line">        <span class="keyword">elif</span> start <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (pred_label_first!=entity <span class="keyword">or</span> (pred_label_first==entity <span class="keyword">and</span> pred_label_second==<span class="string">&#x27;B&#x27;</span>)):</span><br><span class="line">            entity_value=[tokenizer.convert_ids_to_tokens([<span class="built_in">id</span>])[<span class="number">0</span>] <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> input_ids[start:i]]</span><br><span class="line">            ner_result.append((start,i-<span class="number">1</span>,entity,<span class="string">&#x27;&#x27;</span>.join(entity_value)))</span><br><span class="line">            <span class="keyword">if</span> pred_label_second==<span class="string">&#x27;B&#x27;</span>:</span><br><span class="line">                start=i</span><br><span class="line">                entity=pred_label_first</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                start=<span class="literal">None</span></span><br><span class="line">                entity=<span class="string">&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> start <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        entity_value=[tokenizer.convert_ids_to_tokens([<span class="built_in">id</span>])[<span class="number">0</span>] <span class="keyword">for</span> <span class="built_in">id</span> <span class="keyword">in</span> input_ids[start:]]</span><br><span class="line">        ner_result.append((start,<span class="built_in">len</span>( )-<span class="number">1</span>,entity,<span class="string">&#x27;&#x27;</span>.join(entity_value)))</span><br><span class="line">    <span class="keyword">return</span> ner_result</span><br><span class="line"></span><br><span class="line">s=<span class="string">&#x27;姚洋：我方的这种做法是对的。特朗普发动关税战以来，我就认为我们要警惕落入特朗普设定的圈圈，或者说是某种意义上的圈套。特朗普现在是不讲什么外交礼仪、外交策略了，如果打个比喻，就像满地打滚，甚至拿砖头往自己头上砸。那对待这样的人，咱们最好的做法是离他远一点儿，因为你越理他，他越来劲，咱们要避免上他的圈套。&#x27;</span></span><br><span class="line">result=ner(s)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><p>output：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2025</span>-05-<span class="number">21</span> 09:<span class="number">20</span>:<span class="number">21</span>,<span class="number">551</span> - modelscope - WARNING - Using branch: master <span class="keyword">as</span> version <span class="keyword">is</span> unstable, use <span class="keyword">with</span> caution</span><br><span class="line">[(<span class="number">14</span>, <span class="number">16</span>, <span class="string">&#x27;PERSON&#x27;</span>, <span class="string">&#x27;特朗普&#x27;</span>), (<span class="number">36</span>, <span class="number">38</span>, <span class="string">&#x27;PERSON&#x27;</span>, <span class="string">&#x27;特朗普&#x27;</span>), (<span class="number">58</span>, <span class="number">60</span>, <span class="string">&#x27;PERSON&#x27;</span>, <span class="string">&#x27;特朗普&#x27;</span>)]</span><br></pre></td></tr></table></figure><p>另：</p><p>torchcrf包安装问题</p><p>解决方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pytorch-crf</span><br></pre></td></tr></table></figure><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>其实本质上NER任务，还是在做分类问题，只是是相对较为复杂的分类问题。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 大模型 </tag>
            
            <tag> Bert </tag>
            
            <tag> Self-Attention </tag>
            
            <tag> NER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型中的三角位置编码实现</title>
      <link href="//2025-05-20-post3_encoding/"/>
      <url>//2025-05-20-post3_encoding/</url>
      
        <content type="html"><![CDATA[<h2 id="三角位置编码公式："><a href="#三角位置编码公式：" class="headerlink" title="三角位置编码公式："></a>三角位置编码公式：</h2><p><img src="/2025-05-20-post3_encoding/encoding.jpg" alt="公式"></p><h2 id="Transformer中嵌入表示-位置编码的实现"><a href="#Transformer中嵌入表示-位置编码的实现" class="headerlink" title="Transformer中嵌入表示 + 位置编码的实现"></a>Transformer中嵌入表示 + 位置编码的实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 词嵌入位置编码实现</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EmbeddingWithPosition</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    vocab_size:词表大小</span></span><br><span class="line"><span class="string">    emb_size: 词向量维度</span></span><br><span class="line"><span class="string">    seq_max_len: 句子最大长度 (人为设定，例如GPT2的最大长度是1024) </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, emb_size, dropout=<span class="number">0.1</span>, seq_max_len=<span class="number">5000</span></span>):</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.seq_emb = nn.Embedding(vocab_size, emb_size) <span class="comment"># 序列中每个token的embedding向量表示</span></span><br><span class="line">        <span class="comment">#  位置编码实现 (硬编码方式)</span></span><br><span class="line">        position_idx = torch.arange(<span class="number">0</span>, seq_max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">        position_emb_fill = position_idx * torch.exp(-torch.arange(<span class="number">0</span>, emb_size, <span class="number">2</span>) * math.log(<span class="number">10000.0</span>) / emb_size) <span class="comment"># 三角位置编码实现</span></span><br><span class="line"></span><br><span class="line">        position_emb = torch.zeros(seq_max_len, emb_size) <span class="comment"># 位置编码 emb_size是嵌入维度大小</span></span><br><span class="line">        position_emb[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position_emb_fill)</span><br><span class="line">        position_emb[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position_emb_fill)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;pos_encoding&#x27;</span>, position_emb) <span class="comment"># 固定参数,不需要train</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line"></span><br><span class="line">        x = <span class="variable language_">self</span>.seq_emb(x) <span class="comment"># 嵌入层表示 (batch_size, seq_len, emb_size)</span></span><br><span class="line">        <span class="comment"># x = x + self.pos_encoding.unsqueeze(0)[:,:x.size()[1],:] # 添加位置编码</span></span><br><span class="line">        x += <span class="variable language_">self</span>.pos_encoding.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">    </span><br></pre></td></tr></table></figure><h2 id="自己动手实现易懂版本"><a href="#自己动手实现易懂版本" class="headerlink" title="自己动手实现易懂版本:"></a>自己动手实现易懂版本:</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> <span class="number">10</span> % <span class="number">2</span> == <span class="number">0</span>,  <span class="string">&quot;wrong assert&quot;</span></span><br><span class="line"><span class="comment"># 如果前面判断正确的话，则不会引发异常；否则，则会引发异常</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">creat_pe_absolute_sincos_embedding_gov</span>(<span class="params">n_pos_vec, dim</span>):</span><br><span class="line">  <span class="keyword">assert</span> dim % <span class="number">2</span> == <span class="number">0</span>, <span class="string">&quot;wrong dim&quot;</span></span><br><span class="line">  position_embedding = torch.zeros(n_pos_vec.numel(), dim, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">  omega = torch.arange(dim//<span class="number">2</span>, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">  omega /= dim/<span class="number">2.</span></span><br><span class="line">  omega = <span class="number">1.</span>/(<span class="number">10000</span>**omega)</span><br><span class="line"></span><br><span class="line">  sita = n_pos_vec[:,<span class="literal">None</span>] @ omega[<span class="literal">None</span>,:]</span><br><span class="line">  emb_sin = torch.sin(sita)</span><br><span class="line">  emb_cos = torch.cos(sita)</span><br><span class="line"></span><br><span class="line">  position_embedding[:,<span class="number">0</span>::<span class="number">2</span>] = emb_sin</span><br><span class="line">  position_embedding[:,<span class="number">1</span>::<span class="number">2</span>] = emb_cos</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> position_embedding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_pe_absulute_sincos_embedding</span>(<span class="params">n_pos_vec, dim</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绝对位置编码</span></span><br><span class="line"><span class="string">    :param n_pos_vec: 位置编码的长度向量</span></span><br><span class="line"><span class="string">    :param dim: 词向量的维度</span></span><br><span class="line"><span class="string">    :return: 位置编码</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> dim % <span class="number">2</span> == <span class="number">0</span>, <span class="string">&quot;dim must be even&quot;</span></span><br><span class="line">    position_embedding = torch.zeros(n_pos_vec.numel(), dim, dtype=torch.<span class="built_in">float</span>) <span class="comment"># 三角函数位置编码</span></span><br><span class="line"></span><br><span class="line">    omega = torch.arange(dim // <span class="number">2</span>, dtype=torch.<span class="built_in">float</span>) <span class="comment"># 0 ~ i, max_i: dim // 2</span></span><br><span class="line">    omega *= <span class="number">2</span></span><br><span class="line">    omega /= dim </span><br><span class="line"></span><br><span class="line">    omega = torch.<span class="built_in">pow</span>(<span class="number">10000</span>, omega) <span class="comment"># 10000^(2i/dim)</span></span><br><span class="line">    omega = <span class="number">1</span> / omega</span><br><span class="line">    omega = omega</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;n_pos_vec shape:&quot;</span>,n_pos_vec.unsqueeze(<span class="number">1</span>).shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;omega shape:&quot;</span>, omega.shape).squeeze</span><br><span class="line"></span><br><span class="line">    position_embedding[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(n_pos_vec.unsqueeze(<span class="number">1</span>) * omega) <span class="comment"># 偶数位置</span></span><br><span class="line">    position_embedding[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(n_pos_vec.unsqueeze(<span class="number">1</span>) * omega) <span class="comment"># 奇数位置</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> position_embedding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    n_pos = <span class="number">4</span></span><br><span class="line">    dim = <span class="number">8</span></span><br><span class="line">    n_pos_vec = torch.arange(n_pos, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    position_embeddding = create_pe_absulute_sincos_embedding(n_pos_vec, dim)</span><br><span class="line">    position_embeddding_1 = creat_pe_absolute_sincos_embedding_gov(n_pos_vec, dim)</span><br><span class="line">    <span class="built_in">print</span>(position_embeddding == position_embeddding_1)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;position embedding shape:&quot;</span>, position_embeddding.shape)</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/Brilliant_liu/article/details/135033645">参考版本</a></p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> Transformer </tag>
            
            <tag> 大模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型中的KVCache技术</title>
      <link href="//2025-05-20-post2-KVCache/"/>
      <url>//2025-05-20-post2-KVCache/</url>
      
        <content type="html"><![CDATA[<h2 id="Transformer中的KVCache优化原理"><a href="#Transformer中的KVCache优化原理" class="headerlink" title="Transformer中的KVCache优化原理"></a>Transformer中的KVCache优化原理</h2><p><em>前记</em>：现在KVCache已经属于是必备的技术了，但是博主发现自己只是听过这个名词，但是并不了解该技术的原理和实现，遂学习记录了本博客</p><h3 id="1-首先KVCache技术有什么用？"><a href="#1-首先KVCache技术有什么用？" class="headerlink" title="1.首先KVCache技术有什么用？"></a>1.首先KVCache技术有什么用？</h3><p>答：KVCache技术主要帮助模型在推理过程，避免重复的计算，从而减少计算量，加快模型推理速度，同时也会带来成本的降低，设想如果是用户使用一款由该模型作为基座的大模型产品，那么更快的推理速度在用户层面会带来更好的用户体验，同时对于产品运营成本也有所降低。</p><h3 id="2-KVCache技术是如何避免掉重复计算的？"><a href="#2-KVCache技术是如何避免掉重复计算的？" class="headerlink" title="2.KVCache技术是如何避免掉重复计算的？"></a>2.KVCache技术是如何避免掉重复计算的？</h3><p>由下图可知,token在输入模型计算的过程中，存在重复计算的部分，可以发现通过前n个token计算结果获得第n+1个token预测，然后通过这n+1个token再输入到网络中来计算第n+2个token，细细一想，聪明的你是不是发现了后面n+1个token计算的时候，前n个token是不是重复计算了，也就是说 n+1个token输入到模型中，实际上前面n个token的计算，和之前只有n个token输入到网络中的计算结果是一样的，这样就带来了重复计算问题，那我们如何避免掉重复计算问题，我们将前n个token的计算结果给缓存下来，那我们就只需要计算新加入这个token，从而大大降低了计算量。</p><p><img src="/2025-05-20-post2-KVCache/post2_1.jpg" alt="LLMs计算"></p><p>可能你看了上面的解释，还是有点云里雾里，不要着急，我们用代码来解释，从代码的结果来直观的来看到运算结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2Tokenizer, GPT2Model</span><br><span class="line">tokenizer = GPT2Tokenizer.from_pretrained(<span class="string">&#x27;gpt2&#x27;</span>)</span><br><span class="line">model = GPT2Model.from_pretrained(<span class="string">&#x27;gpt2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># text: &quot;The quick brown fox jumps over the lazy&quot;</span></span><br><span class="line">tokens = [[<span class="number">464</span>, <span class="number">2068</span>, <span class="number">7586</span>, <span class="number">21831</span>, <span class="number">18045</span>, <span class="number">625</span>, <span class="number">262</span>, <span class="number">16931</span>]]</span><br><span class="line">input_n = torch.tensor(tokens)</span><br><span class="line">output_n = model(input_ids=input_n, output_hidden_states=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># text: &quot; dog&quot;</span></span><br><span class="line">tokens[<span class="number">0</span>].append(<span class="number">3290</span>)</span><br><span class="line">input_n_plus_1 = torch.tensor(tokens)</span><br><span class="line">output_n_plus_1 = model(input_ids=input_n_plus_1, output_hidden_states=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, (hidden_n, hidden_n_plus_1) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(output_n.hidden_states, output_n_plus_1.hidden_states)):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;layer <span class="subst">&#123;i&#125;</span>, max difference <span class="subst">&#123;(hidden_n - hidden_n_plus_1[:, :-<span class="number">1</span>, :]).<span class="built_in">abs</span>().<span class="built_in">max</span>().item()&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">assert</span> torch.allclose(hidden_n, hidden_n_plus_1[:, :-<span class="number">1</span>, :], atol=<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure><p>运算结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">layer <span class="number">0</span>, <span class="built_in">max</span> difference <span class="number">0.0</span></span><br><span class="line">layer <span class="number">1</span>, <span class="built_in">max</span> difference <span class="number">5.7220458984375e-06</span></span><br><span class="line">layer <span class="number">2</span>, <span class="built_in">max</span> difference <span class="number">5.7220458984375e-06</span></span><br><span class="line">layer <span class="number">3</span>, <span class="built_in">max</span> difference <span class="number">7.62939453125e-06</span></span><br><span class="line">layer <span class="number">4</span>, <span class="built_in">max</span> difference <span class="number">2.86102294921875e-05</span></span><br><span class="line">layer <span class="number">5</span>, <span class="built_in">max</span> difference <span class="number">1.9073486328125e-05</span></span><br><span class="line">layer <span class="number">6</span>, <span class="built_in">max</span> difference <span class="number">9.5367431640625e-06</span></span><br><span class="line">layer <span class="number">7</span>, <span class="built_in">max</span> difference <span class="number">1.9073486328125e-05</span></span><br><span class="line">layer <span class="number">8</span>, <span class="built_in">max</span> difference <span class="number">2.6702880859375e-05</span></span><br><span class="line">layer <span class="number">9</span>, <span class="built_in">max</span> difference <span class="number">2.6702880859375e-05</span></span><br><span class="line">layer <span class="number">10</span>, <span class="built_in">max</span> difference <span class="number">2.6702880859375e-05</span></span><br><span class="line">layer <span class="number">11</span>, <span class="built_in">max</span> difference <span class="number">3.0517578125e-05</span></span><br><span class="line">layer <span class="number">12</span>, <span class="built_in">max</span> difference <span class="number">3.0517578125e-05</span></span><br></pre></td></tr></table></figure><p>因此，我们可以用空间来换时间，牺牲掉内存空间来换取更快的推理速度。</p><h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h3><p>[1]: <a href="https://zhuanlan.zhihu.com/p/686183300">https://zhuanlan.zhihu.com/p/686183300</a>“KVCache”<br>[2]: <a href="https://github.com/owenliang/pytorch-transformer/tree/kvcache#">https://github.com/owenliang/pytorch-transformer/tree/kvcache#</a>  “KVCache项目”</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> Transformer </tag>
            
            <tag> KVCache </tag>
            
            <tag> LLMs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention is all you need.</title>
      <link href="//2025-05-17-post1/"/>
      <url>//2025-05-17-post1/</url>
      
        <content type="html"><![CDATA[<p>德语-&gt;英语项目：</p><p><a href="https://github.com/TCcjx/pytorch_transformer-remake">https://github.com/TCcjx/pytorch_transformer-remake</a></p><p>项目目录结构（文件说明）：</p><p>.data(文件夹)：数据集Multi30K</p><p>checkpoints(文件夹):训练权重文件保存处</p><p>config.py：全局配置文件，DEVICE以及输入token的最大长度</p><p>dataset.py：数据预处理文件，构建德语和英语词表，实现德语和英语的词元token和IDX的一一隐射，以及德语和英语句子预处理函数（输入德语和英语句子，返回分词后的词元列表信息，以及词元ID列表）</p><p>multihead_attn.py: 构建多头注意力机制模块，这里的实现同时也考虑了解码器中第二个多头注意力机制模块的代码复用，在编码器和解码器的多头注意力机制模块中都可以复用这个多头注意力机制的模块</p><p>encoder_block.py：编码器模块的构建</p><p>encoder.py：编码器的实现，同时自动处理PAD掩码矩阵，再传入encoder_block中，实现多个encoder_block的堆叠使用</p><p>decoder_block.py:解码器模块的构建</p><p>decoder.py: 解码器的实现，同时实现两个掩码矩阵，第一个掩码矩阵主要是PAD掩码以及三角掩码（遮蔽后续词元）， 第二个掩码矩阵主要是为了遮蔽encoder隐藏表示中的PAD填充，防止解码器 Q到PAD</p><p>transformer:将编码器和解码器组装到一起，得到最后的词表大小的输出预测，用于预测下一个词元</p><p>train.py:训练文件</p><p>evaluation:预测效果测试评估文件</p><h1 id="知识碎片-交叉熵损失函数"><a href="#知识碎片-交叉熵损失函数" class="headerlink" title="知识碎片-交叉熵损失函数"></a>知识碎片-交叉熵损失函数</h1><p>在 PyTorch 中，<code>CrossEntropyLoss</code> 是最常用的损失函数之一，适用于分类任务。下面详细介绍其传参方式和注意事项：</p><h3 id="基本参数"><a href="#基本参数" class="headerlink" title="基本参数"></a><strong>基本参数</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CrossEntropyLoss(</span><br><span class="line">    weight=<span class="literal">None</span>,           <span class="comment"># 各类别的权重，用于不平衡数据集</span></span><br><span class="line">    size_average=<span class="literal">None</span>,     <span class="comment"># 已弃用</span></span><br><span class="line">    ignore_index=-<span class="number">100</span>,     <span class="comment"># 忽略的目标值，不参与损失计算</span></span><br><span class="line">    reduce=<span class="literal">None</span>,           <span class="comment"># 已弃用</span></span><br><span class="line">    reduction=<span class="string">&#x27;mean&#x27;</span>,      <span class="comment"># 损失的聚合方式：&#x27;none&#x27;|&#x27;mean&#x27;|&#x27;sum&#x27;</span></span><br><span class="line">    label_smoothing=<span class="number">0.0</span>    <span class="comment"># 标签平滑参数，0.0 表示不使用</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="输入要求"><a href="#输入要求" class="headerlink" title="输入要求"></a><strong>输入要求</strong></h3><p><code>CrossEntropyLoss</code> 要求两个输入：</p><ol><li><p><strong>预测值 (</strong><code>**input**</code><strong>)</strong>：</p><ol><li>形状：<code>(N, C, d1, d2, ...)</code>，其中：<ul><li><code>N</code>：批次大小（Batch size）</li><li><code>C</code>：类别数（Number of classes）</li><li><code>d1, d2, ...</code>：可选的空间维度（如序列长度、高度、宽度等）</li></ul></li><li>类型：<strong>未归一化的对数概率（logits）</strong>，不需要经过 Softmax。</li></ol></li><li><p><strong>目标值 (</strong><code>**target**</code><strong>)</strong>：</p><ol><li>形状：<code>(N, d1, d2, ...)</code>（不包含类别维度）</li><li>类型：<strong>类别索引</strong>（整数，范围 <code>0</code> 到 <code>C-1</code>）。</li></ol></li></ol><h3 id="常见场景示例"><a href="#常见场景示例" class="headerlink" title="常见场景示例"></a><strong>常见场景示例</strong></h3><h4 id="1-标准分类（二维输入）"><a href="#1-标准分类（二维输入）" class="headerlink" title="1. 标准分类（二维输入）"></a>1. <strong>标准分类（二维输入）</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入: (batch_size, num_classes)</span></span><br><span class="line">logits = torch.randn(<span class="number">3</span>, <span class="number">5</span>)  <span class="comment"># 3个样本，5个类别</span></span><br><span class="line">target = torch.tensor([<span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>])  <span class="comment"># 每个样本的真实类别</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss = loss_fn(logits, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Loss: <span class="subst">&#123;loss.item()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="2-序列分类（三维输入）"><a href="#2-序列分类（三维输入）" class="headerlink" title="2. 序列分类（三维输入）"></a>2. <strong>序列分类（三维输入）</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入: (batch_size, sequence_length, num_classes)</span></span><br><span class="line">logits = torch.randn(<span class="number">2</span>, <span class="number">10</span>, <span class="number">5</span>)  <span class="comment"># 2个样本，序列长度10，5个类别</span></span><br><span class="line">target = torch.randint(<span class="number">0</span>, <span class="number">5</span>, (<span class="number">2</span>, <span class="number">10</span>))  <span class="comment"># 每个位置的真实类别</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要调整维度：将类别维度移到第2维</span></span><br><span class="line">logits = logits.transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (2, 5, 10)</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss = loss_fn(logits, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Loss: <span class="subst">&#123;loss.item()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h4 id="3-图像分割（四维输入）"><a href="#3-图像分割（四维输入）" class="headerlink" title="3. 图像分割（四维输入）"></a>3. <strong>图像分割（四维输入）</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入: (batch_size, num_classes, height, width)</span></span><br><span class="line">logits = torch.randn(<span class="number">2</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">32</span>)  <span class="comment"># 2张图像，5个类别，32x32尺寸</span></span><br><span class="line">target = torch.randint(<span class="number">0</span>, <span class="number">5</span>, (<span class="number">2</span>, <span class="number">32</span>, <span class="number">32</span>))  <span class="comment"># 每个像素的真实类别</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()</span><br><span class="line">loss = loss_fn(logits, target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Loss: <span class="subst">&#123;loss.item()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="关键注意事项"><a href="#关键注意事项" class="headerlink" title="关键注意事项"></a><strong>关键注意事项</strong></h3><ol><li><p><strong>无需手动 Softmax</strong>：<code>CrossEntropyLoss</code> 内部包含 <code>LogSoftmax</code> 和 <code>NLLLoss</code>，输入直接使用未归一化的 logits 即可。</p></li><li><p><strong>目标值格式</strong>：必须是类别索引（整数），而非 one-hot 编码。</p></li><li><p><strong>权重平衡</strong>：通过 <code>weight</code> 参数可为不同类别设置权重，处理类别不平衡问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例：为少数类设置更高权重</span></span><br><span class="line">weights = torch.tensor([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>])  <span class="comment"># 第1类权重为2，其余为1</span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss(weight=weights)</span><br></pre></td></tr></table></figure></li><li><p><strong>忽略特定类别</strong>：通过 <code>ignore_index</code> 参数可忽略某些目标值（如填充标记）。</p></li></ol><h3 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a><strong>常见错误</strong></h3><ul><li><strong>错误1</strong>：输入经过了 Softmax 处理。<ul><li><strong>解决</strong>：直接使用模型输出的 logits。</li></ul></li><li><strong>错误2</strong>：目标值包含超出类别范围的索引。<ul><li><strong>解决</strong>：确保目标值范围在 <code>0</code> 到 <code>C-1</code> 之间。</li></ul></li><li><strong>错误3</strong>：维度不匹配（如类别维度位置错误）。<ul><li><strong>解决</strong>：使用 <code>transpose</code> 或 <code>permute</code> 调整维度。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
